{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ca1c67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a089137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scanning 5 PDFs from 2025...\n",
      "\n",
      "Scanning 5 PDFs from 2024...\n",
      "\n",
      "Scanning 5 PDFs from 2023...\n",
      "\n",
      "Detected 12 unique table layouts across samples.\n",
      "\n",
      "Template hash: 1de9480f697fb8a9feb721ba3f64359f\n",
      "Example file: 2025-07-14.pdf\n",
      "Columns: ['Unnamed: 0', 'Unnamed: 1', 'Rs./kg', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4']\n",
      "\n",
      "Template hash: f77f79383807770100ff96ea90031055\n",
      "Example file: 2025-08-18.pdf\n",
      "Columns: ['s', 'Rs./kg', 'Unnamed: 0', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4']\n",
      "\n",
      "Template hash: f6e6f9ab42ea996b869f70058c692fb7\n",
      "Example file: 2025-09-22.pdf\n",
      "Columns: ['Unnamed: 0', 'Rs./kg', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3']\n",
      "\n",
      "Template hash: 7f3d5432ae71079a291595318cee250a\n",
      "Example file: 2025-10-16.pdf\n",
      "Columns: ['Unnamed: 0', 'Rs./kg', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5']\n",
      "\n",
      "Template hash: dd073a0505ac5aba85754bfb1474244c\n",
      "Example file: 2025-06-11.pdf\n",
      "Columns: ['s', 'Unnamed: 0', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8']\n",
      "\n",
      "Template hash: 4166c890be3a02e4901d5f6d6d82bcaa\n",
      "Example file: 2024-01-01.pdf\n",
      "Columns: ['Unnamed: 0', 'Rs./kg', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8']\n",
      "\n",
      "Template hash: be55725588a4d7200672fea800fda6b9\n",
      "Example file: 2024-12-18.pdf\n",
      "Columns: ['Unnamed: 0', 'Rs./kg', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7']\n",
      "\n",
      "Template hash: 645d44c65d6aa8b83aa1c796fe40c10d\n",
      "Example file: 2024-10-02.pdf\n",
      "Columns: ['Unnamed: 0', 'Rs./kg', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4']\n",
      "\n",
      "Template hash: 8ef0c6dc561b737aeaee050e9cf9db0a\n",
      "Example file: 2023-03-21.pdf\n",
      "Columns: ['Unnamed: 0', 'Rs./kg', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6']\n",
      "\n",
      "Template hash: c162181a4967a3239fd76e81d8ae31b5\n",
      "Example file: 2023-01-19.pdf\n",
      "Columns: ['Price of Beans declined further in Rs./kg', 'Unnamed: 0', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9']\n",
      "\n",
      "Template hash: b0bbc51f60c546df669ba4e2b26fa7b4\n",
      "Example file: 2023-01-31.pdf\n",
      "Columns: ['les', 'Unnamed: 0', 'Rs./kg', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7']\n",
      "\n",
      "Template hash: 737565ad80447b534cc3ba764e82cc3f\n",
      "Example file: 2023-07-14.pdf\n",
      "Columns: ['Eliya and Kandy areas.', '150', 'Unnamed: 0', '14-Jun', '14-Jun.1', '14-Jun.2', '14-Jun.3']\n"
     ]
    }
   ],
   "source": [
    "import tabula\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import hashlib\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_template_signature(pdf_path):\n",
    "    try:\n",
    "        tables = tabula.read_pdf(pdf_path, pages=1, multiple_tables=True)\n",
    "        if not tables:\n",
    "            return None\n",
    "\n",
    "        df = tables[0]\n",
    "        header_line = \"|\".join(str(c).strip().lower() for c in df.columns)\n",
    "        header_hash = hashlib.md5(header_line.encode()).hexdigest()\n",
    "        return {\n",
    "            \"file\": pdf_path.name,\n",
    "            \"headers\": list(df.columns),\n",
    "            \"hash\": header_hash\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {pdf_path.name}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "root = Path(\"../data/raw\")\n",
    "year_folders = [f for f in root.iterdir() if f.is_dir()]\n",
    "\n",
    "signatures = []\n",
    "\n",
    "for year_folder in year_folders:\n",
    "    pdfs = list(year_folder.glob(\"*.pdf\"))\n",
    "    sample = random.sample(pdfs, min(len(pdfs), 5))  # pick 5 or fewer if not enough\n",
    "    print(f\"\\nScanning {len(sample)} PDFs from {year_folder.name}...\")\n",
    "    \n",
    "    for pdf in sample:\n",
    "        sig = get_template_signature(pdf)\n",
    "        if sig:\n",
    "            signatures.append(sig)\n",
    "\n",
    "# Group and summarize\n",
    "by_template = defaultdict(list)\n",
    "for sig in signatures:\n",
    "    by_template[sig[\"hash\"]].append(sig[\"file\"])\n",
    "\n",
    "print(f\"\\nDetected {len(by_template)} unique table layouts across samples.\")\n",
    "for h, files in by_template.items():\n",
    "    print(\"\\nTemplate hash:\", h)\n",
    "    print(\"Example file:\", files[0])\n",
    "    headers = [s['headers'] for s in signatures if s['hash'] == h][0]\n",
    "    print(\"Columns:\", headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b88ac31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“‚ Scanning 5 PDFs from 2025...\n",
      "\n",
      "ğŸ“‚ Scanning 5 PDFs from 2024...\n",
      "\n",
      "ğŸ“‚ Scanning 5 PDFs from 2023...\n",
      "\n",
      "ğŸ§© Detected 10 unique table layouts across samples.\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Template hash: 7f3d5432ae71079a291595318cee250a\n",
      "Example file: 2025-10-02.pdf\n",
      "Columns: ['Unnamed: 0', 'Rs./kg', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5']\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Template hash: 4166c890be3a02e4901d5f6d6d82bcaa\n",
      "Example file: 2025-10-13.pdf\n",
      "Columns: ['Unnamed: 0', 'Rs./kg', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8']\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Template hash: f53962ef4124e803fff59a30ca4f6f97\n",
      "Example file: 2025-04-07.pdf\n",
      "Columns: ['s', 'Unnamed: 0', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7']\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Template hash: be55725588a4d7200672fea800fda6b9\n",
      "Example file: 2025-08-26.pdf\n",
      "Columns: ['Unnamed: 0', 'Rs./kg', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7']\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Template hash: a9e43d341cf0e5634d23f7eaa613f2e1\n",
      "Example file: 2025-01-02.pdf\n",
      "Columns: ['s', 'Rs./kg', 'Unnamed: 0', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3']\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Template hash: af2f46ca611ba4562236720c24d86e30\n",
      "Example file: 2024-04-15.pdf\n",
      "Columns: ['Unnamed: 0', 'Wednesday due to favourable 125', 'Unnamed: 1', 'q', 'Unnamed: 2', 'Unnamed: 3', 'Pettah :', '250.00', '230.00', 'Unnamed: 4']\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Template hash: 5806bad8419ba8d4fd90addf6dfbb336\n",
      "Example file: 2024-06-12.pdf\n",
      "Columns: ['Unnamed: 0', 'Rs./kg', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9']\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Template hash: 8ef0c6dc561b737aeaee050e9cf9db0a\n",
      "Example file: 2024-10-21.pdf\n",
      "Columns: ['Unnamed: 0', 'Rs./kg', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6']\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Template hash: 8f3bdb9b25249eb29c1b5484d91d3248\n",
      "Example file: 2023-04-26.pdf\n",
      "Columns: ['Unnamed: 0', 'Rs./kg', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10']\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Template hash: cbf5d5a3977af00f2d579ade70d6daa2\n",
      "Example file: 2023-11-22.pdf\n",
      "Columns: ['bles', 'Unnamed: 0', 'Rs./kg', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6']\n",
      "\n",
      "âœ… Saved layout_summary.csv â€” open it to inspect headers and years.\n",
      "   Use this to identify repeating patterns and name your templates, e.g.:\n",
      "   TEMPLATE_A (2023 early), TEMPLATE_B (2024 mid), TEMPLATE_C (2025 onward)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# PDF Layout Profiler (Tabula-based)\n",
    "# Detects and groups distinct table layouts across PDF samples\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "import tabula\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import hashlib\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# STEP 1 â€” Extract a \"signature\" from a single PDF\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def get_template_signature(pdf_path):\n",
    "    \"\"\"Reads the first table in the first page and returns its column signature.\"\"\"\n",
    "    try:\n",
    "        tables = tabula.read_pdf(pdf_path, pages=1, multiple_tables=True)\n",
    "        if not tables:\n",
    "            return None\n",
    "\n",
    "        df = tables[0]\n",
    "        header_line = \"|\".join(str(c).strip().lower() for c in df.columns)\n",
    "        header_hash = hashlib.md5(header_line.encode()).hexdigest()\n",
    "\n",
    "        return {\n",
    "            \"file\": pdf_path.name,\n",
    "            \"year\": pdf_path.parent.name,\n",
    "            \"headers\": list(df.columns),\n",
    "            \"hash\": header_hash,\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Error reading {pdf_path.name}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# STEP 2 â€” Sample PDFs from each year folder\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "root = Path(\"../data/raw\")\n",
    "year_folders = [f for f in root.iterdir() if f.is_dir()]\n",
    "\n",
    "signatures = []\n",
    "\n",
    "for year_folder in year_folders:\n",
    "    pdfs = list(year_folder.glob(\"*.pdf\"))\n",
    "    if not pdfs:\n",
    "        continue\n",
    "\n",
    "    # Take 5 random samples (or fewer if limited)\n",
    "    sample = random.sample(pdfs, min(len(pdfs), 5))\n",
    "    print(f\"\\nğŸ“‚ Scanning {len(sample)} PDFs from {year_folder.name}...\")\n",
    "\n",
    "    for pdf in sample:\n",
    "        sig = get_template_signature(pdf)\n",
    "        if sig:\n",
    "            signatures.append(sig)\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# STEP 3 â€” Group by unique header hash\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "by_template = defaultdict(list)\n",
    "for sig in signatures:\n",
    "    by_template[sig[\"hash\"]].append(sig[\"file\"])\n",
    "\n",
    "print(f\"\\nğŸ§© Detected {len(by_template)} unique table layouts across samples.\\n\")\n",
    "\n",
    "for h, files in by_template.items():\n",
    "    example = files[0]\n",
    "    headers = [s['headers'] for s in signatures if s['hash'] == h][0]\n",
    "    print(\"â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "    print(f\"Template hash: {h}\")\n",
    "    print(f\"Example file: {example}\")\n",
    "    print(\"Columns:\", headers)\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# STEP 4 â€” Save summary for manual inspection\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "df_summary = pd.DataFrame(signatures)\n",
    "df_summary.to_csv(\"layout_summary.csv\", index=False)\n",
    "\n",
    "print(\"\\nâœ… Saved layout_summary.csv â€” open it to inspect headers and years.\")\n",
    "print(\"   Use this to identify repeating patterns and name your templates, e.g.:\")\n",
    "print(\"   TEMPLATE_A (2023 early), TEMPLATE_B (2024 mid), TEMPLATE_C (2025 onward)\\n\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# STEP 5 â€” Optional: define a template map\n",
    "# (Youâ€™ll fill this manually after inspection)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "TEMPLATE_MAP = {\n",
    "    # \"hashcode\": \"template_label\",\n",
    "    # Example:\n",
    "    # \"1de9480f697fb8a9feb721ba3f64359f\": \"2025_layout_A\",\n",
    "}\n",
    "\n",
    "def route_parser(pdf_path, header_hash):\n",
    "    parser = TEMPLATE_MAP.get(header_hash)\n",
    "    if not parser:\n",
    "        print(f\"âš ï¸ Unknown layout for {pdf_path.name} (hash={header_hash})\")\n",
    "        return None\n",
    "\n",
    "    # Later: route to correct parse function\n",
    "    print(f\"â†’ Parsing {pdf_path.name} using {parser}\")\n",
    "    # return parse_template_x(pdf_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b83a27b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>year</th>\n",
       "      <th>headers</th>\n",
       "      <th>hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-10-02.pdf</td>\n",
       "      <td>2025</td>\n",
       "      <td>[Unnamed: 0, Rs./kg, Unnamed: 1, Unnamed: 2, U...</td>\n",
       "      <td>7f3d5432ae71079a291595318cee250a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-10-13.pdf</td>\n",
       "      <td>2025</td>\n",
       "      <td>[Unnamed: 0, Rs./kg, Unnamed: 1, Unnamed: 2, U...</td>\n",
       "      <td>4166c890be3a02e4901d5f6d6d82bcaa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-04-07.pdf</td>\n",
       "      <td>2025</td>\n",
       "      <td>[s, Unnamed: 0, Unnamed: 1, Unnamed: 2, Unname...</td>\n",
       "      <td>f53962ef4124e803fff59a30ca4f6f97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-08-26.pdf</td>\n",
       "      <td>2025</td>\n",
       "      <td>[Unnamed: 0, Rs./kg, Unnamed: 1, Unnamed: 2, U...</td>\n",
       "      <td>be55725588a4d7200672fea800fda6b9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-02.pdf</td>\n",
       "      <td>2025</td>\n",
       "      <td>[s, Rs./kg, Unnamed: 0, Unnamed: 1, Unnamed: 2...</td>\n",
       "      <td>a9e43d341cf0e5634d23f7eaa613f2e1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             file  year                                            headers  \\\n",
       "0  2025-10-02.pdf  2025  [Unnamed: 0, Rs./kg, Unnamed: 1, Unnamed: 2, U...   \n",
       "1  2025-10-13.pdf  2025  [Unnamed: 0, Rs./kg, Unnamed: 1, Unnamed: 2, U...   \n",
       "2  2025-04-07.pdf  2025  [s, Unnamed: 0, Unnamed: 1, Unnamed: 2, Unname...   \n",
       "3  2025-08-26.pdf  2025  [Unnamed: 0, Rs./kg, Unnamed: 1, Unnamed: 2, U...   \n",
       "4  2025-01-02.pdf  2025  [s, Rs./kg, Unnamed: 0, Unnamed: 1, Unnamed: 2...   \n",
       "\n",
       "                               hash  \n",
       "0  7f3d5432ae71079a291595318cee250a  \n",
       "1  4166c890be3a02e4901d5f6d6d82bcaa  \n",
       "2  f53962ef4124e803fff59a30ca4f6f97  \n",
       "3  be55725588a4d7200672fea800fda6b9  \n",
       "4  a9e43d341cf0e5634d23f7eaa613f2e1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3e5e7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 12 columns â†’ ['item', 'unit', 'wholesale_pettah_today', 'wholesale_dambulla_today', 'retail_pettah_today', 'retail_dambulla_today', 'retail_nara_today', 'extra_0', 'extra_1', 'extra_2', 'extra_3', 'extra_4']\n",
      "      item  unit  wholesale_pettah_today  wholesale_dambulla_today  \\\n",
      "0      NaN  Item                     NaN                       NaN   \n",
      "1      NaN   NaN                     NaN                       NaN   \n",
      "2      NaN   NaN                     NaN                       NaN   \n",
      "3      NaN   NaN                     NaN                       NaN   \n",
      "4    Beans   NaN                     NaN                     650.0   \n",
      "5   Carrot   NaN                     NaN                     250.0   \n",
      "6  Cabbage   NaN                     NaN                     130.0   \n",
      "7   Tomato   NaN                     NaN                     120.0   \n",
      "8  Brinjal   NaN                     NaN                     300.0   \n",
      "9  Pumpkin   NaN                     NaN                      80.0   \n",
      "\n",
      "   retail_pettah_today  retail_dambulla_today  retail_nara_today  extra_0  \\\n",
      "0                  NaN                    NaN                NaN      NaN   \n",
      "1                  NaN                    NaN                NaN      NaN   \n",
      "2                  NaN                    NaN                NaN      NaN   \n",
      "3                  NaN                    NaN                NaN      NaN   \n",
      "4                650.0                  480.0              700.0      NaN   \n",
      "5                350.0                  235.0              400.0      NaN   \n",
      "6                200.0                  145.0              320.0      NaN   \n",
      "7                170.0                  120.0              200.0      NaN   \n",
      "8                350.0                  255.0              480.0      NaN   \n",
      "9                120.0                   85.0              120.0      NaN   \n",
      "\n",
      "   extra_1  extra_2  extra_3  extra_4  \n",
      "0      NaN      NaN      NaN      NaN  \n",
      "1      NaN      NaN      NaN      NaN  \n",
      "2      NaN      NaN      NaN      NaN  \n",
      "3      NaN      NaN      NaN      NaN  \n",
      "4      NaN      NaN      NaN      NaN  \n",
      "5      NaN      NaN      NaN      NaN  \n",
      "6      NaN      NaN      NaN      NaN  \n",
      "7      NaN      NaN      NaN      NaN  \n",
      "8      NaN      NaN      NaN      NaN  \n",
      "9      NaN      NaN      NaN      NaN  \n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f680c111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wholesale and Retail Prices: Selected Food Commodities - 30 July 2025\n",
      "Wholesale Prices Retail Prices\n",
      "Item Unit\n",
      "Pettah Dambulla Pettah Dambulla Narahenpita\n",
      "Yesterday Today Yesterday Today Yesterday Today Yesterday Today Yesterday Today\n",
      "V E G E T A B L E S\n",
      "Beans Rs./kg 6 50.00 6 00.00 4 50.00 4 75.00 7 00.00 6 50.00 4 80.00 5 05.00 7 00.00 7 00.00\n",
      "Carrot Rs./kg 2 50.00 3 00.00 2 05.00 2 90.00 3 00.00 3 50.00 2 35.00 3 20.00 4 00.00 4 00.00\n",
      "Cabbage Rs./kg 1 30.00 1 50.00 1 15.00 1 25.00 1 80.00 2 00.00 1 45.00 1 55.00 3 20.00 3 20.00\n",
      "Tomato Rs./kg 1 20.00 1 20.00 9 0.00 9 0.00 1 70.00 1 70.00 1 20.00 1 20.00 2 00.00 2 00.00\n",
      "Brinjal Rs./kg 3 00.00 3 00.00 2 25.00 2 40.00 3 50.00 3 50.00 2 55.00 2 70.00 4 80.00 4 80.00\n",
      "Pumpkin Rs./kg 8 0.00 8 0.00 5 5.00 5 5.00 1 20.00 1 20.00 8 5.00 8 5.00 1 20.00 1 20.00\n",
      "Snake gourd Rs./kg 1 30.00 1 30.00 9 0.00 9 0.00 1 80.00 1 80.00 1 20.00 1 20.00 3 60.00 3 60.00\n",
      "Green Chilli Rs./kg 2 00.00 2 00.00 2 40.00 2 25.00 2 50.00 2 50.00 2 70.00 2 55.00 6 00.0\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(text[:\u001b[38;5;241m1000\u001b[39m])  \u001b[38;5;66;03m# print first 1000 chars\u001b[39;00m\n\u001b[1;32m      8\u001b[0m lines \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39msplitlines()\n\u001b[0;32m----> 9\u001b[0m start_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlines\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRICE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ml\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m end_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(i \u001b[38;5;28;01mfor\u001b[39;00m i, l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(lines) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFISH\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m l)\n\u001b[1;32m     11\u001b[0m section \u001b[38;5;241m=\u001b[39m lines[start_idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m:end_idx]\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "\n",
    "with pdfplumber.open(\"../data/raw/2025/2025-07-30.pdf\") as pdf:\n",
    "    page = pdf.pages[1]\n",
    "    text = page.extract_text()\n",
    "    print(text[:1000])  # print first 1000 chars\n",
    "\n",
    "lines = text.splitlines()\n",
    "start_idx = next(i for i, l in enumerate(lines) if \"RICE\" in l)\n",
    "end_idx = next(i for i, l in enumerate(lines) if \"FISH\" in l)\n",
    "section = lines[start_idx+1:end_idx]\n",
    "print(\"\\n\".join(section))\n",
    "\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "\n",
    "def extract_section_between(pdf_path, start_word, end_word, page_num=1):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        page = pdf.pages[page_num - 1]\n",
    "        chars = page.chars  # every character with x/y coords\n",
    "\n",
    "    # Helper: find y positions of our target words built from letters\n",
    "    def find_word_y(chars, target):\n",
    "        target = target.upper()\n",
    "        text = \"\".join(c[\"text\"].upper() for c in chars)\n",
    "        if not all(letter in text for letter in target):\n",
    "            return None\n",
    "        # find sequence of letters visually aligned\n",
    "        letters = [c for c in chars if c[\"text\"].upper() in target]\n",
    "        # cluster by line (y coord)\n",
    "        y_map = {}\n",
    "        for c in letters:\n",
    "            y_key = round(c[\"top\"], -1)\n",
    "            y_map.setdefault(y_key, []).append(c[\"text\"])\n",
    "        for y, seq in y_map.items():\n",
    "            joined = \"\".join(seq)\n",
    "            if target in joined:\n",
    "                return y\n",
    "        return None\n",
    "\n",
    "    start_y = find_word_y(chars, start_word)\n",
    "    end_y = find_word_y(chars, end_word)\n",
    "    if start_y is None or end_y is None:\n",
    "        raise ValueError(\"Couldn't locate start or end word â€” likely letter-split text.\")\n",
    "\n",
    "    if start_y > end_y:\n",
    "        start_y, end_y = end_y, start_y\n",
    "\n",
    "    section_chars = [c for c in chars if start_y < c[\"top\"] < end_y]\n",
    "\n",
    "    # group by y coord into lines\n",
    "    lines = {}\n",
    "    for c in section_chars:\n",
    "        y_key = round(c[\"top\"], -1)\n",
    "        lines.setdefault(y_key, []).append(c)\n",
    "\n",
    "    data = []\n",
    "    for y, line_chars in sorted(lines.items()):\n",
    "        sorted_line = sorted(line_chars, key=lambda x: x[\"x0\"])\n",
    "        data.append(\"\".join(ch[\"text\"] for ch in sorted_line))\n",
    "    return data\n",
    "\n",
    "section = extract_section_between(\"../data/raw/2025/2025-07-30.pdf\", \"RICE\", \"FISH\", page_num=2)\n",
    "print(\"\\n\".join(section[:30]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59b45bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "\n",
    "def extract_section_between(pdf_path, start_word, end_word, page_num=1):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        page = pdf.pages[page_num - 1]\n",
    "        chars = page.chars  # each letter with x/y coords\n",
    "\n",
    "    def find_line_y(chars, target_letters):\n",
    "        \"\"\"Find approximate y position of a target word built from its letters.\"\"\"\n",
    "        target_letters = list(target_letters.upper())\n",
    "        y_map = {}\n",
    "        for c in chars:\n",
    "            y_key = round(c[\"top\"], -1)\n",
    "            y_map.setdefault(y_key, []).append(c[\"text\"].upper())\n",
    "\n",
    "        for y, letters in y_map.items():\n",
    "            joined = \"\".join(letters)\n",
    "            if all(t in joined for t in target_letters):\n",
    "                return y\n",
    "        return None\n",
    "\n",
    "    start_y = find_line_y(chars, start_word)\n",
    "    end_y = find_line_y(chars, end_word)\n",
    "\n",
    "    if start_y is None or end_y is None:\n",
    "        raise ValueError(\"Couldnâ€™t locate start or end word â€” text likely letter-split.\")\n",
    "\n",
    "    # Ensure top < bottom\n",
    "    if start_y > end_y:\n",
    "        start_y, end_y = end_y, start_y\n",
    "\n",
    "    # Filter characters between those Y ranges\n",
    "    section_chars = [c for c in chars if start_y < c[\"top\"] < end_y]\n",
    "\n",
    "    # Group chars into lines by Y position\n",
    "    lines = {}\n",
    "    for c in section_chars:\n",
    "        y_key = round(c[\"top\"], -1)\n",
    "        lines.setdefault(y_key, []).append(c)\n",
    "\n",
    "    # Sort each line horizontally and build text\n",
    "    data = []\n",
    "    for y, line_chars in sorted(lines.items()):\n",
    "        sorted_line = sorted(line_chars, key=lambda x: x[\"x0\"])\n",
    "        line_text = \"\".join(ch[\"text\"] for ch in sorted_line)\n",
    "        data.append(line_text.strip())\n",
    "    return data\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# TEST IT HERE\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "pdf_path = \"../data/raw/2025/2025-07-30.pdf\"  # change path as needed\n",
    "section = extract_section_between(pdf_path, \"RICE\", \"FISH\", page_num=2)\n",
    "\n",
    "print(\"\\n\".join(section[:30]))  # show first 30 lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b2696892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.0 Wholesale and Retail Prices: Selected Food Commodities   -30 July 2025\n",
      "50.0 Wholesale PricesRetail Prices\n",
      "60.0 PettahDambulla NarahenpitaItemUnitPettahDambulla \n",
      "90.0 V  E  G  E  T  A  B  L  E  S\n",
      "110.0 BeansRs./kg650.00            600.00        450.00           475.00        700.00           650.00         480.00           505.00        700.00           700.00          \n",
      "120.0 CarrotRs./kg250.00            300.00        205.00           290.00        300.00           350.00         235.00           320.00        400.00           400.00          \n",
      "130.0 CabbageRs./kg130.00            150.00        115.00           125.00        180.00           200.00         145.00           155.00        320.00           320.00          \n",
      "150.0 TomatoRs./kg120.00            120.00        90.00             90.00          170.00           170.00         120.00           120.00        200.00           200.00          \n",
      "160.0 BrinjalRs./kg300.00            300.00        225.00           240.00        350.00           350.00         255.00           270.00        480.00           480.00          \n",
      "170.0 PumpkinRs./kg80.00              80.00          55.00             55.00          120.00           120.00         85.00             85.00          120.00           120.00          \n",
      "190.0 Snake gourdRs./kg130.00            130.00        90.00             90.00          180.00           180.00         120.00           120.00        360.00           360.00          \n",
      "200.0 Green ChilliRs./kg200.00            200.00        240.00           225.00        250.00           250.00         270.00           255.00        600.00           600.00          \n",
      "210.0 LimeRs./kg150.00            200.00        165.00           165.00        200.00           250.00         195.00           195.00        500.00           500.00          \n",
      "220.0 O  T  H  E  R\n",
      "240.0 Red Onion (Local)Rs./kg300.00            270.00        245.00           n.a.300.00           300.00         265.00           n.a.n.a.n.a.\n",
      "250.0 Red Onion (lmp)Rs./kgn.a.210.00        240.00           245.00        n.a.n.a.260.00           265.00        520.00           520.00          \n",
      "260.0 Big Onion (Local)Rs./kgn.a.n.a.n.a.n.a.n.a.n.a.n.a.n.a.n.a.n.a.\n",
      "280.0 Big Onion (Imp)Rs./kg100.00            91.00          98.00             105.00        130.00           130.00         118.00           125.00        140.00           140.00          \n",
      "290.0 Potato (Local)Rs./kg325.00            340.00        290.00           290.00        400.00           400.00         310.00           310.00        440.00           440.00          \n",
      "300.0 Potato (Imp)Rs./kg160.00            157.00        145.00           n.a.200.00           200.00         165.00           n.a.200.00           200.00          \n",
      "320.0 Dried Chilli (Imp)Rs./kg525.00            525.00        545.00           375.00        600.00           600.00         575.00           405.00        800.00           800.00          \n",
      "330.0 Coconut (Avg.)Rs./Nut160.00            165.00        105.00           113.00        175.00           175.00         110.00           118.00        165.00           165.00          \n",
      "340.0 Coconut oil Rs./Ltr810.00            810.00        867.00           867.00         866.00           866.00          \n",
      "360.0 Red DhalRs./kg245.00            245.00        270.00           270.00         280.00           280.00          \n",
      "370.0 Sugar (White)Rs./kg209.00            209.00        220.00           220.00         240.00           240.00          \n",
      "380.0 Egg (White)Rs./Each28.00              28.00          28.50             28.50            30.00             30.00            \n",
      "400.0 Katta (Imp)Rs./kg1,600.00         1,600.00     1,950.00        1,950.00      n.a.n.a.\n",
      "410.0 Sprat (Imp)Rs./kg850.00            850.00        1,000.00        1,000.00      n.a.n.a.\n",
      "420.0 F  R  U  I  T  S\n",
      "430.0 Banana (Sour)Rs./kg\n",
      "450.0 PapawRs./kg120.00            120.00        85.00             88.00          170.00           170.00         115.00           118.00        200.00           200.00          \n",
      "460.0 PineappleRs./kgn.a.n.a.275.00           275.00        225.00           225.00         305.00           305.00        350.00           350.00          \n",
      "470.0 Apple (Imp)Rs./Each\n",
      "490.0 Orange (Imp)Rs./Each190.00           190.00         250.00           250.00          \n",
      "500.0 R  I  C  E\n",
      "530.0 SambaRs./kg235.00            235.00        234.00           234.00        240.00           240.00         244.00           244.00        240.00           240.00          \n",
      "540.0 NaduRs./kg213.00            213.00        208.00           208.00        230.00           230.00         235.00           235.00        230.00           230.00          \n",
      "550.0 Kekulu (White)Rs./kg203.00            203.00        200.00           198.00        220.00           220.00         220.00           220.00        220.00           220.00          \n",
      "560.0 Kekulu (Red)Rs./kg\n",
      "580.0 Ponni Samba (Imp)Rs./kg230.00            230.00        n.a.n.a.233.00           233.00         n.a.n.a.\n",
      "590.0 Nadu (Imp)Rs./kg210.00            210.00        n.a.n.a.220.00           220.00         n.a.n.a.\n",
      "600.0 Kekulu (White) (Imp)Rs./kg\n",
      "620.0 F  I  S  H\n",
      "640.0 KelawallaRs./kg1,300.00         1,350.00     1,150.00        1,150.00     1,740.00        1,740.00    2,460.00        2,460.00       \n",
      "660.0 ThalapathRs./kg2,000.00         1,900.00     1,650.00        1,650.00     2,160.00        2,160.00    2,500.00        2,500.00       \n",
      "670.0 BalayaRs./kg1,000.00         1,100.00     n.a.n.a.n.a.n.a.1,380.00        1,380.00       \n",
      "680.0 ParawRs./kg1,400.00         1,300.00     1,420.00        n.a.2,310.00        n.a.1,860.00        n.a.\n",
      "700.0 SalayaRs./kg400.00            250.00        460.00           360.00        610.00           490.00        540.00           460.00          \n",
      "710.0 HurullaRs./kg900.00            900.00        670.00           620.00        880.00           820.00        1,480.00        1,180.00       \n",
      "720.0 LinnaRs./kg600.00            600.00        600.00           620.00        790.00           790.00        800.00           800.00          \n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "\n",
    "pdf_path = \"../data/raw/2025/2025-07-30.pdf\"\n",
    "page_num = 2\n",
    "\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    page = pdf.pages[page_num - 1]\n",
    "    chars = page.chars\n",
    "\n",
    "# Group characters by approximate line\n",
    "y_map = {}\n",
    "for c in chars:\n",
    "    y_key = round(c[\"top\"], -1)\n",
    "    y_map.setdefault(y_key, []).append(c[\"text\"])\n",
    "\n",
    "for y, texts in sorted(y_map.items()):\n",
    "    line = \"\".join(texts)\n",
    "    if \"R\" in line or \"I\" in line or \"C\" in line or \"E\" in line:\n",
    "        print(y, line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3e525526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marandagahamula\n",
      "SambaRs./kg235.00            235.00        234.00           234.00        240.00           240.00         244.00           244.00        240.00           240.00\n",
      "NaduRs./kg213.00            213.00        208.00           208.00        230.00           230.00         235.00           235.00        230.00           230.00\n",
      "Kekulu (White)Rs./kg203.00            203.00        200.00           198.00        220.00           220.00         220.00           220.00        220.00           220.00\n",
      "Kekulu (Red)Rs./kg\n",
      "203.00            203.00        195.00           195.00        220.00           220.00         220.00           220.00        210.00           210.00\n",
      "Ponni Samba (Imp)Rs./kg230.00            230.00        n.a.n.a.233.00           233.00         n.a.n.a.\n",
      "Nadu (Imp)Rs./kg210.00            210.00        n.a.n.a.220.00           220.00         n.a.n.a.\n",
      "Kekulu (White) (Imp)Rs./kg\n",
      "208.00            208.00        n.a.n.a.220.00           220.00         210.00           210.00\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "\n",
    "def extract_section_between(pdf_path, start_letters, end_letters, page_num=2):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        page = pdf.pages[page_num - 1]\n",
    "        chars = page.chars\n",
    "\n",
    "    # Group by approximate line y-position\n",
    "    y_map = {}\n",
    "    for c in chars:\n",
    "        y_key = round(c[\"top\"], -1)\n",
    "        y_map.setdefault(y_key, []).append(c[\"text\"])\n",
    "    \n",
    "    # Rebuild text lines\n",
    "    lines = []\n",
    "    for y, texts in sorted(y_map.items()):\n",
    "        line_text = \"\".join(texts).replace(\"\\xa0\", \"\").strip()\n",
    "        lines.append((y, line_text))\n",
    "    \n",
    "    # Find start and end positions\n",
    "    def find_line_y(target):\n",
    "        for y, text in lines:\n",
    "            if all(ch in text for ch in target.replace(\" \", \"\")):  # handles spaced \"R I C E\"\n",
    "                return y\n",
    "        return None\n",
    "\n",
    "    start_y = find_line_y(start_letters)\n",
    "    end_y = find_line_y(end_letters)\n",
    "    if not start_y or not end_y:\n",
    "        raise ValueError(\"Could not find start or end header.\")\n",
    "\n",
    "    # Collect lines in between\n",
    "    section = [txt for y, txt in lines if start_y < y < end_y]\n",
    "    return section\n",
    "\n",
    "# â”€â”€â”€ Run test â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "pdf_path = \"../data/raw/2025/2025-07-30.pdf\"\n",
    "rice_section = extract_section_between(pdf_path, \"RICE\", \"FISH\", page_num=2)\n",
    "\n",
    "print(\"\\n\".join(rice_section))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8d184315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def parse_price_section(section_lines):\n",
    "    \"\"\"Convert raw text lines (e.g. from RICE section) into a clean DataFrame.\"\"\"\n",
    "    merged_lines = []\n",
    "    for line in section_lines:\n",
    "        if not line.strip() or \"Marandagahamula\" in line:\n",
    "            continue\n",
    "        # Merge multi-line items (like Kekulu (Red))\n",
    "        if re.match(r\"^[A-Za-z]\", line):\n",
    "            merged_lines.append(line)\n",
    "        elif merged_lines:\n",
    "            merged_lines[-1] += \" \" + line\n",
    "\n",
    "    parsed_rows = []\n",
    "    for line in merged_lines:\n",
    "        clean = line.replace(\",\", \"\").replace(\"â€¦\", \"\").replace(\"â€”\", \"-\")\n",
    "\n",
    "        # FIXED REGEX: keep n.a. together, also Rs./kg etc.\n",
    "        tokens = re.findall(\n",
    "            r\"n\\.a\\.|N\\.A\\.|Rs\\.\\/[A-Za-z]+|[A-Za-z()]+|[0-9]+\\.?[0-9]*\",\n",
    "            clean,\n",
    "        )\n",
    "\n",
    "        if len(tokens) < 3:\n",
    "            continue\n",
    "\n",
    "        # find where Rs./kg, Rs./Each, etc. appears\n",
    "        try:\n",
    "            idx_unit = next(i for i, t in enumerate(tokens) if \"Rs\" in t or \"rs\" in t)\n",
    "        except StopIteration:\n",
    "            continue\n",
    "\n",
    "        item = \" \".join(tokens[:idx_unit])\n",
    "        unit = tokens[idx_unit]\n",
    "        values = tokens[idx_unit + 1:]\n",
    "\n",
    "        parsed_rows.append([item, unit] + values)\n",
    "\n",
    "    # Pad to equal column count\n",
    "    max_len = max(len(r) for r in parsed_rows)\n",
    "    for r in parsed_rows:\n",
    "        r += [None] * (max_len - len(r))\n",
    "\n",
    "    cols = [\"Item\", \"Unit\"] + [f\"Col{i}\" for i in range(1, max_len - 1)]\n",
    "    df = pd.DataFrame(parsed_rows, columns=cols)\n",
    "\n",
    "    # Convert n.a. to NaN, numbers to floats\n",
    "    df = df.replace({\"n.a.\": None, \"N.A.\": None})\n",
    "    for col in df.columns[2:]:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aa2d2b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Item       Unit  Col1   Col2   Col3   Col4   Col5   Col6   Col7  \\\n",
      "0                    SambaRs   NaN  235.0  235.0  234.0  234.0  240.0  240.0   \n",
      "1                     NaduRs   NaN  213.0  213.0  208.0  208.0  230.0  230.0   \n",
      "2          Kekulu  (White)Rs   NaN  203.0  203.0  200.0  198.0  220.0  220.0   \n",
      "3          Kekulu    (Red)Rs   NaN  203.0  203.0  195.0  195.0  220.0  220.0   \n",
      "4     Ponni Samba    (Imp)Rs   NaN  230.0  230.0    NaN    NaN  233.0  233.0   \n",
      "5            Nadu    (Imp)Rs   NaN  210.0  210.0    NaN    NaN  220.0  220.0   \n",
      "6  Kekulu (White)    (Imp)Rs   NaN  208.0  208.0    NaN    NaN  220.0  220.0   \n",
      "\n",
      "    Col8   Col9  Col10  Col11  \n",
      "0  244.0  244.0  240.0  240.0  \n",
      "1  235.0  235.0  230.0  230.0  \n",
      "2  220.0  220.0  220.0  220.0  \n",
      "3  220.0  220.0  210.0  210.0  \n",
      "4    NaN    NaN    NaN    NaN  \n",
      "5    NaN    NaN    NaN    NaN  \n",
      "6  210.0  210.0    NaN    NaN  \n",
      "\n",
      "âœ… Saved to rice_clean.csv\n"
     ]
    }
   ],
   "source": [
    "pdf_path = \"../data/raw/2025/2025-07-30.pdf\"\n",
    "rice_section = extract_section_between(pdf_path, \"RICE\", \"FISH\", page_num=2)\n",
    "\n",
    "df_rice = parse_price_section(rice_section)\n",
    "print(df_rice)\n",
    "df_rice.to_csv(\"rice_clean.csv\", index=False)\n",
    "print(\"\\nâœ… Saved to rice_clean.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca6f3763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "      <th>Col5</th>\n",
       "      <th>Col6</th>\n",
       "      <th>Col7</th>\n",
       "      <th>Col8</th>\n",
       "      <th>Col9</th>\n",
       "      <th>Col10</th>\n",
       "      <th>Col11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>SambaRs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>235.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>NaduRs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>213.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kekulu</td>\n",
       "      <td>(White)Rs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>203.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kekulu</td>\n",
       "      <td>(Red)Rs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>203.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ponni Samba</td>\n",
       "      <td>(Imp)Rs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>230.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>233.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nadu</td>\n",
       "      <td>(Imp)Rs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>210.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>220.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kekulu (White)</td>\n",
       "      <td>(Imp)Rs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>208.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>220.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Item       Unit  Col1   Col2   Col3   Col4   Col5   Col6   Col7  \\\n",
       "0                    SambaRs   NaN  235.0  235.0  234.0  234.0  240.0  240.0   \n",
       "1                     NaduRs   NaN  213.0  213.0  208.0  208.0  230.0  230.0   \n",
       "2          Kekulu  (White)Rs   NaN  203.0  203.0  200.0  198.0  220.0  220.0   \n",
       "3          Kekulu    (Red)Rs   NaN  203.0  203.0  195.0  195.0  220.0  220.0   \n",
       "4     Ponni Samba    (Imp)Rs   NaN  230.0  230.0    NaN    NaN  233.0  233.0   \n",
       "5            Nadu    (Imp)Rs   NaN  210.0  210.0    NaN    NaN  220.0  220.0   \n",
       "6  Kekulu (White)    (Imp)Rs   NaN  208.0  208.0    NaN    NaN  220.0  220.0   \n",
       "\n",
       "    Col8   Col9  Col10  Col11  \n",
       "0  244.0  244.0  240.0  240.0  \n",
       "1  235.0  235.0  230.0  230.0  \n",
       "2  220.0  220.0  220.0  220.0  \n",
       "3  220.0  220.0  210.0  210.0  \n",
       "4    NaN    NaN    NaN    NaN  \n",
       "5    NaN    NaN    NaN    NaN  \n",
       "6  210.0  210.0    NaN    NaN  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rice.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1b1227e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def parse_price_section(section_lines):\n",
    "    \"\"\"Convert text section (like RICE) into a clean structured DataFrame.\"\"\"\n",
    "    merged_lines = []\n",
    "    for line in section_lines:\n",
    "        if not line.strip() or \"Marandagahamula\" in line:\n",
    "            continue\n",
    "        # merge broken lines (e.g., Kekulu (Red))\n",
    "        if re.match(r\"^[A-Za-z]\", line):\n",
    "            merged_lines.append(line)\n",
    "        elif merged_lines:\n",
    "            merged_lines[-1] += \" \" + line\n",
    "\n",
    "    parsed_rows = []\n",
    "\n",
    "    for line in merged_lines:\n",
    "        # â”€â”€ Basic cleanup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        clean = line.replace(\",\", \"\").replace(\"â€¦\", \"\").replace(\"â€”\", \"-\")\n",
    "\n",
    "        # ğŸ’¡ Inject missing space before Rs. (e.g. \"SambaRs./kg\" â†’ \"Samba Rs./kg\")\n",
    "        clean = re.sub(r\"([a-zA-Z)])(Rs\\.)\", r\"\\1 \\2\", clean)\n",
    "\n",
    "        # âœ¨ Fix glued prices like \"130.00132.00\" â†’ \"130.00 132.00\"\n",
    "        clean = re.sub(r\"(\\d+\\.\\d{1,2})(?=\\d+\\.\\d{1,2})\", r\"\\1 \", clean)\n",
    "\n",
    "        # â”€â”€ Tokenize text â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        tokens = re.findall(\n",
    "            r\"n\\.a\\.|N\\.A\\.|Rs\\.\\/[A-Za-z]+|[A-Za-z()]+|\\d+\\.\\d{1,2}|\\d+\",\n",
    "            clean,\n",
    "        )\n",
    "\n",
    "        if len(tokens) < 3:\n",
    "            continue\n",
    "\n",
    "        # find Rs./something as the unit\n",
    "        try:\n",
    "            idx_unit = next(i for i, t in enumerate(tokens) if \"Rs\" in t)\n",
    "        except StopIteration:\n",
    "            continue\n",
    "\n",
    "        item = \" \".join(tokens[:idx_unit])\n",
    "        unit = tokens[idx_unit]\n",
    "        values = tokens[idx_unit + 1:]\n",
    "\n",
    "        # â”€â”€ FIX: handle glued or partial decimals robustly â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        split_values = []\n",
    "        for v in values:\n",
    "            # Extract all valid numbers inside each token\n",
    "            nums = re.findall(r\"\\d+\\.\\d{1,2}\", v)\n",
    "            if nums:\n",
    "                split_values.extend(nums)\n",
    "            elif v.lower() == \"n.a.\":\n",
    "                split_values.append(None)\n",
    "            else:\n",
    "                split_values.append(v)\n",
    "\n",
    "        parsed_rows.append([item.strip(), unit.strip()] + split_values)\n",
    "\n",
    "    # â”€â”€ Pad rows for consistent DataFrame shape â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    if not parsed_rows:\n",
    "        return pd.DataFrame(columns=[\"Item\", \"Unit\"])\n",
    "    max_len = max(len(r) for r in parsed_rows)\n",
    "    for r in parsed_rows:\n",
    "        r += [None] * (max_len - len(r))\n",
    "\n",
    "    df = pd.DataFrame(parsed_rows, columns=[\"Item\", \"Unit\"] + [f\"Col{i}\" for i in range(1, max_len - 1)])\n",
    "\n",
    "    # â”€â”€ Clean leftover noise â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    df[\"Item\"] = df[\"Item\"].str.replace(r\"Rs$\", \"\", regex=True).str.strip()\n",
    "    df[\"Unit\"] = df[\"Unit\"].str.replace(r\"[^A-Za-z/.]\", \"\", regex=True).str.strip()\n",
    "\n",
    "    # â”€â”€ Catch hidden Rs inside Item (e.g., \"Samba Rs./kg\") â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    mask = (df[\"Unit\"].eq(\"\") | df[\"Unit\"].isna()) & df[\"Item\"].str.contains(\"Rs\", na=False)\n",
    "    for i, row in df.loc[mask].iterrows():\n",
    "        match = re.search(r\"(.*?)(Rs\\.\\/[A-Za-z]+)\", row[\"Item\"])\n",
    "        if match:\n",
    "            df.at[i, \"Item\"] = match.group(1).strip()\n",
    "            df.at[i, \"Unit\"] = match.group(2).strip()\n",
    "\n",
    "    # â”€â”€ Replace n.a. with NaN and convert to numbers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    df = df.replace({\"n.a.\": None, \"N.A.\": None})\n",
    "    for col in df.columns[2:]:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c395af90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Item    Unit   Col1   Col2   Col3   Col4   Col5   Col6  \\\n",
      "0                 Samba  Rs./kg  150.0  152.0  155.0  155.0    NaN    NaN   \n",
      "1                  Nadu  Rs./kg  138.0  141.0  140.0  140.0    NaN    NaN   \n",
      "2        Kekulu (White)  Rs./kg  139.0  137.0  128.0  128.0    NaN    NaN   \n",
      "3          Kekulu (Red)  Rs./kg  128.0  133.0  123.0  138.0    NaN    NaN   \n",
      "4     Ponni Samba (Imp)  Rs./kg  127.0  127.0  121.0  121.0  130.0  130.0   \n",
      "5            Nadu (Imp)  Rs./kg  125.0  120.0  116.0  116.0    NaN    NaN   \n",
      "6  Kekulu (White) (Imp)  Rs./kg  118.0  122.0  104.0  104.0  120.0    NaN   \n",
      "\n",
      "    Col7   Col8   Col9  Col10  \n",
      "0  155.0  175.0  170.0  165.0  \n",
      "1  145.0  160.0  145.0  160.0  \n",
      "2  133.0  145.0  165.0  150.0  \n",
      "3  120.0  145.0  140.0  130.0  \n",
      "4  140.0  140.0    NaN    NaN  \n",
      "5  120.0  130.0    NaN    NaN  \n",
      "6  115.0  130.0    NaN    NaN  \n",
      "\n",
      "âœ… Saved to rice_clean.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "      <th>Col5</th>\n",
       "      <th>Col6</th>\n",
       "      <th>Col7</th>\n",
       "      <th>Col8</th>\n",
       "      <th>Col9</th>\n",
       "      <th>Col10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Samba</td>\n",
       "      <td>Rs./kg</td>\n",
       "      <td>150.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>155.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>165.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nadu</td>\n",
       "      <td>Rs./kg</td>\n",
       "      <td>138.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kekulu (White)</td>\n",
       "      <td>Rs./kg</td>\n",
       "      <td>139.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>133.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kekulu (Red)</td>\n",
       "      <td>Rs./kg</td>\n",
       "      <td>128.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ponni Samba (Imp)</td>\n",
       "      <td>Rs./kg</td>\n",
       "      <td>127.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nadu (Imp)</td>\n",
       "      <td>Rs./kg</td>\n",
       "      <td>125.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kekulu (White) (Imp)</td>\n",
       "      <td>Rs./kg</td>\n",
       "      <td>118.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Item    Unit   Col1   Col2   Col3   Col4   Col5   Col6  \\\n",
       "0                 Samba  Rs./kg  150.0  152.0  155.0  155.0    NaN    NaN   \n",
       "1                  Nadu  Rs./kg  138.0  141.0  140.0  140.0    NaN    NaN   \n",
       "2        Kekulu (White)  Rs./kg  139.0  137.0  128.0  128.0    NaN    NaN   \n",
       "3          Kekulu (Red)  Rs./kg  128.0  133.0  123.0  138.0    NaN    NaN   \n",
       "4     Ponni Samba (Imp)  Rs./kg  127.0  127.0  121.0  121.0  130.0  130.0   \n",
       "5            Nadu (Imp)  Rs./kg  125.0  120.0  116.0  116.0    NaN    NaN   \n",
       "6  Kekulu (White) (Imp)  Rs./kg  118.0  122.0  104.0  104.0  120.0    NaN   \n",
       "\n",
       "    Col7   Col8   Col9  Col10  \n",
       "0  155.0  175.0  170.0  165.0  \n",
       "1  145.0  160.0  145.0  160.0  \n",
       "2  133.0  145.0  165.0  150.0  \n",
       "3  120.0  145.0  140.0  130.0  \n",
       "4  140.0  140.0    NaN    NaN  \n",
       "5  120.0  130.0    NaN    NaN  \n",
       "6  115.0  130.0    NaN    NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pdf_path = \"../data/raw/2022/2022-01-04.pdf\"\n",
    "rice_section = extract_section_between(pdf_path, \"RICE\", \"FISH\", page_num=2)\n",
    "\n",
    "df_rice = parse_price_section(rice_section)\n",
    "print(df_rice)\n",
    "df_rice.to_csv(\"rice_clean.csv\", index=False)\n",
    "print(\"\\nâœ… Saved to rice_clean.csv\")\n",
    "display(df_rice.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "45beee7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dynamic_column_names(section_lines):\n",
    "    text = \" \".join(section_lines[:40]).lower()\n",
    "    columns = [\"item\", \"unit\"]\n",
    "\n",
    "    # default locations\n",
    "    wholesale_locs = [\"pettah\", \"dambulla\"]\n",
    "    retail_locs = [\"pettah\", \"dambulla\", \"narahenpita\"]\n",
    "\n",
    "    # detect Marandagahamula case\n",
    "    if \"marandagahamula\" in text:\n",
    "        wholesale_locs.insert(0, \"marandagahamula\")\n",
    "\n",
    "    for loc in wholesale_locs:\n",
    "        columns += [f\"wholesale_{loc}_yesterday\", f\"wholesale_{loc}_today\"]\n",
    "\n",
    "    for loc in retail_locs:\n",
    "        columns += [f\"retail_{loc}_yesterday\", f\"retail_{loc}_today\"]\n",
    "\n",
    "    return columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b13eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = get_dynamic_column_names(section_lines)\n",
    "cols = cols[:len(df_rice.columns)]  # trim if fewer columns exist\n",
    "df_rice.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "baf9e2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Saved to rice_clean.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>unit</th>\n",
       "      <th>wholesale_pettah_yesterday</th>\n",
       "      <th>wholesale_pettah_today</th>\n",
       "      <th>wholesale_marandagahamula_yesterday</th>\n",
       "      <th>wholesale_marandagahamula_today</th>\n",
       "      <th>retail_pettah_yesterday</th>\n",
       "      <th>retail_pettah_today</th>\n",
       "      <th>retail_dambulla_yesterday</th>\n",
       "      <th>retail_dambulla_today</th>\n",
       "      <th>retail_narahenpita_yesterday</th>\n",
       "      <th>retail_narahenpita_today</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Samba</td>\n",
       "      <td>Rs./kg</td>\n",
       "      <td>213.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nadu</td>\n",
       "      <td>Rs./kg</td>\n",
       "      <td>203.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kekulu (White)</td>\n",
       "      <td>Rs./kg</td>\n",
       "      <td>193.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kekulu (Red)</td>\n",
       "      <td>Rs./kg</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>210.0</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ponni Samba (Imp)</td>\n",
       "      <td>Rs./kg</td>\n",
       "      <td>206.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nadu (Imp)</td>\n",
       "      <td>Rs./kg</td>\n",
       "      <td>178.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kekulu (White) (Imp)</td>\n",
       "      <td>Rs./kg</td>\n",
       "      <td>173.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   item    unit  wholesale_pettah_yesterday  \\\n",
       "0                 Samba  Rs./kg                       213.0   \n",
       "1                  Nadu  Rs./kg                       203.0   \n",
       "2        Kekulu (White)  Rs./kg                       193.0   \n",
       "3          Kekulu (Red)  Rs./kg                       200.0   \n",
       "4     Ponni Samba (Imp)  Rs./kg                       206.0   \n",
       "5            Nadu (Imp)  Rs./kg                       178.0   \n",
       "6  Kekulu (White) (Imp)  Rs./kg                       173.0   \n",
       "\n",
       "   wholesale_pettah_today  wholesale_marandagahamula_yesterday  \\\n",
       "0                   213.0                                198.0   \n",
       "1                   203.0                                193.0   \n",
       "2                   195.0                                183.0   \n",
       "3                   200.0                                205.0   \n",
       "4                   203.0                                194.0   \n",
       "5                   178.0                                174.0   \n",
       "6                   170.0                                170.0   \n",
       "\n",
       "   wholesale_marandagahamula_today  retail_pettah_yesterday  \\\n",
       "0                            198.0                    220.0   \n",
       "1                            193.0                    215.0   \n",
       "2                            183.0                    210.0   \n",
       "3                            205.0                    215.0   \n",
       "4                            195.0                    210.0   \n",
       "5                            174.0                    200.0   \n",
       "6                            170.0                    200.0   \n",
       "\n",
       "   retail_pettah_today  retail_dambulla_yesterday  retail_dambulla_today  \\\n",
       "0                220.0                      240.0                  240.0   \n",
       "1                215.0                      208.0                  208.0   \n",
       "2                210.0                      190.0                  190.0   \n",
       "3                215.0                        NaN                    NaN   \n",
       "4                210.0                      230.0                  230.0   \n",
       "5                200.0                      205.0                  205.0   \n",
       "6                200.0                      195.0                  195.0   \n",
       "\n",
       "   retail_narahenpita_yesterday  retail_narahenpita_today  \n",
       "0                         225.0                     225.0  \n",
       "1                         220.0                     220.0  \n",
       "2                         210.0                     210.0  \n",
       "3                         210.0                     210.0  \n",
       "4                           NaN                       NaN  \n",
       "5                           NaN                       NaN  \n",
       "6                           NaN                       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 1ï¸âƒ£ Parse RICE section into structured DataFrame\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def parse_price_section(section_lines):\n",
    "    merged_lines = []\n",
    "    for line in section_lines:\n",
    "        if not line.strip() or \"Marandagahamula\" in line:\n",
    "            continue\n",
    "        # merge broken item lines\n",
    "        if re.match(r\"^[A-Za-z]\", line):\n",
    "            merged_lines.append(line)\n",
    "        elif merged_lines:\n",
    "            merged_lines[-1] += \" \" + line\n",
    "\n",
    "    parsed_rows = []\n",
    "\n",
    "    for line in merged_lines:\n",
    "        # clean up text\n",
    "        clean = line.replace(\",\", \"\").replace(\"â€¦\", \"\").replace(\"â€”\", \"-\")\n",
    "        clean = re.sub(r\"([a-zA-Z)])(Rs\\.)\", r\"\\1 \\2\", clean)\n",
    "        # fix glued numbers like \"130.00132.00\"\n",
    "        clean = re.sub(r\"(\\d+\\.\\d{1,2})(?=\\d+\\.\\d{1,2})\", r\"\\1 \", clean)\n",
    "\n",
    "        # tokenize text into words and numbers\n",
    "        tokens = re.findall(\n",
    "            r\"n\\.a\\.|N\\.A\\.|Rs\\.\\/[A-Za-z]+|[A-Za-z()]+|\\d+\\.\\d{1,2}|\\d+\",\n",
    "            clean,\n",
    "        )\n",
    "        if len(tokens) < 3:\n",
    "            continue\n",
    "\n",
    "        # detect Rs./kg as unit marker\n",
    "        try:\n",
    "            idx_unit = next(i for i, t in enumerate(tokens) if \"Rs\" in t)\n",
    "        except StopIteration:\n",
    "            continue\n",
    "\n",
    "        item = \" \".join(tokens[:idx_unit])\n",
    "        unit = tokens[idx_unit]\n",
    "        values = tokens[idx_unit + 1:]\n",
    "\n",
    "        split_values = []\n",
    "        for v in values:\n",
    "            nums = re.findall(r\"\\d+\\.\\d{1,2}\", v)\n",
    "            if nums:\n",
    "                split_values.extend(nums)\n",
    "            elif v.lower() == \"n.a.\":\n",
    "                split_values.append(None)\n",
    "            else:\n",
    "                split_values.append(v)\n",
    "\n",
    "        parsed_rows.append([item.strip(), unit.strip()] + split_values)\n",
    "\n",
    "    if not parsed_rows:\n",
    "        return pd.DataFrame(columns=[\"Item\", \"Unit\"])\n",
    "\n",
    "    # normalize row lengths\n",
    "    max_len = max(len(r) for r in parsed_rows)\n",
    "    for r in parsed_rows:\n",
    "        r += [None] * (max_len - len(r))\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        parsed_rows,\n",
    "        columns=[\"Item\", \"Unit\"] + [f\"Col{i}\" for i in range(1, max_len - 1)],\n",
    "    )\n",
    "\n",
    "    # cleanup columns\n",
    "    df[\"Item\"] = df[\"Item\"].str.replace(r\"Rs$\", \"\", regex=True).str.strip()\n",
    "    df[\"Unit\"] = df[\"Unit\"].str.replace(r\"[^A-Za-z/.]\", \"\", regex=True).str.strip()\n",
    "\n",
    "    # fix cases like \"Samba Rs./kg\"\n",
    "    mask = (df[\"Unit\"].eq(\"\") | df[\"Unit\"].isna()) & df[\"Item\"].str.contains(\"Rs\", na=False)\n",
    "    for i, row in df.loc[mask].iterrows():\n",
    "        match = re.search(r\"(.*?)(Rs\\.\\/[A-Za-z]+)\", row[\"Item\"])\n",
    "        if match:\n",
    "            df.at[i, \"Item\"] = match.group(1).strip()\n",
    "            df.at[i, \"Unit\"] = match.group(2).strip()\n",
    "\n",
    "    # convert to numeric\n",
    "    df = df.replace({\"n.a.\": None, \"N.A.\": None})\n",
    "    for col in df.columns[2:]:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 2ï¸âƒ£ Dynamic column name generator\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def get_dynamic_column_names(section_lines):\n",
    "    text = \" \".join(section_lines[:40]).lower()\n",
    "    columns = [\"item\", \"unit\"]\n",
    "\n",
    "    # Default locations\n",
    "    wholesale_locs = [\"pettah\"]\n",
    "    retail_locs = [\"pettah\", \"dambulla\", \"narahenpita\"]\n",
    "\n",
    "    # If Marandagahamula is mentioned, insert it right after Pettah\n",
    "    if \"marandagahamula\" in text:\n",
    "        wholesale_locs += [\"marandagahamula\"]\n",
    "\n",
    "    # # Add Dambulla *after* Marandagahamula (or Pettah if not present)\n",
    "    # wholesale_locs += [\"dambulla\"]\n",
    "\n",
    "    # Build wholesale + retail headers\n",
    "    for loc in wholesale_locs:\n",
    "        columns += [f\"wholesale_{loc}_yesterday\", f\"wholesale_{loc}_today\"]\n",
    "\n",
    "    for loc in retail_locs:\n",
    "        columns += [f\"retail_{loc}_yesterday\", f\"retail_{loc}_today\"]\n",
    "\n",
    "    return columns\n",
    "\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 3ï¸âƒ£ Combine both steps for one clean call\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def extract_and_parse_rice(pdf_path, start=\"RICE\", end=\"FISH\", page_num=2):\n",
    "    \"\"\"Extracts RICE section and returns a labeled DataFrame.\"\"\"\n",
    "    section_lines = extract_section_between(pdf_path, start, end, page_num)\n",
    "    df = parse_price_section(section_lines)\n",
    "\n",
    "    cols = get_dynamic_column_names(section_lines)\n",
    "    cols = cols[:len(df.columns)]\n",
    "    df.columns = cols\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 4ï¸âƒ£ Example run\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "pdf_path = \"../data/raw/2023/2023-01-04.pdf\"\n",
    "df_rice = extract_and_parse_rice(pdf_path)\n",
    "\n",
    "df_rice.to_csv(\"rice_clean.csv\", index=False)\n",
    "print(\"\\nâœ… Saved to rice_clean.csv\")\n",
    "display(df_rice.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2359f2",
   "metadata": {},
   "source": [
    "# Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3ff33450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RAW EXTRACTED LINES ---\n",
      "Marandagahamula\n",
      "SambaRs./kg213.00          213.00          198.00          198.00          220.00          220.00          240.00          240.00          225.00          225.00\n",
      "NaduRs./kg203.00          203.00          193.00          193.00          215.00          215.00          208.00          208.00          220.00          220.00\n",
      "Kekulu (White)Rs./kg193.00          195.00          183.00          183.00          210.00          210.00          190.00          190.00          210.00          210.00\n",
      "Kekulu (Red)Rs./kg200.00          200.00          205.00          205.00          215.00          215.00          n.a.n.a.210.00          210.00\n",
      "Ponni Samba (Imp)Rs./kg206.00          203.00          194.00          195.00          210.00          210.00          230.00          230.00\n",
      "Nadu (Imp)Rs./kg\n",
      "178.00          178.00          174.00          174.00          200.00          200.00          205.00          205.00\n",
      "Kekulu (White) (Imp)Rs./kg173.00          170.00          170.00          170.00          200.00          200.00          195.00          195.00\n"
     ]
    }
   ],
   "source": [
    "pdf_path = \"../data/raw/2023/2023-01-04.pdf\"\n",
    "rice_section = extract_section_between(pdf_path, \"RICE\", \"FISH\", page_num=2)\n",
    "\n",
    "print(\"\\n--- RAW EXTRACTED LINES ---\")\n",
    "for line in rice_section[:10]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9e358775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "      <th>Col5</th>\n",
       "      <th>Col6</th>\n",
       "      <th>Col7</th>\n",
       "      <th>Col8</th>\n",
       "      <th>Col9</th>\n",
       "      <th>Col10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Samba</td>\n",
       "      <td>Rs./kg</td>\n",
       "      <td>213.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nadu</td>\n",
       "      <td>Rs./kg</td>\n",
       "      <td>203.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kekulu (White)</td>\n",
       "      <td>Rs./kg</td>\n",
       "      <td>193.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kekulu (Red)</td>\n",
       "      <td>Rs./kg</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>210.0</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ponni Samba (Imp)</td>\n",
       "      <td>Rs./kg</td>\n",
       "      <td>206.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nadu (Imp)</td>\n",
       "      <td>Rs./kg</td>\n",
       "      <td>178.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kekulu (White) (Imp)</td>\n",
       "      <td>Rs./kg</td>\n",
       "      <td>173.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Item    Unit   Col1   Col2   Col3   Col4   Col5   Col6  \\\n",
       "0                 Samba  Rs./kg  213.0  213.0  198.0  198.0  220.0  220.0   \n",
       "1                  Nadu  Rs./kg  203.0  203.0  193.0  193.0  215.0  215.0   \n",
       "2        Kekulu (White)  Rs./kg  193.0  195.0  183.0  183.0  210.0  210.0   \n",
       "3          Kekulu (Red)  Rs./kg  200.0  200.0  205.0  205.0  215.0  215.0   \n",
       "4     Ponni Samba (Imp)  Rs./kg  206.0  203.0  194.0  195.0  210.0  210.0   \n",
       "5            Nadu (Imp)  Rs./kg  178.0  178.0  174.0  174.0  200.0  200.0   \n",
       "6  Kekulu (White) (Imp)  Rs./kg  173.0  170.0  170.0  170.0  200.0  200.0   \n",
       "\n",
       "    Col7   Col8   Col9  Col10  \n",
       "0  240.0  240.0  225.0  225.0  \n",
       "1  208.0  208.0  220.0  220.0  \n",
       "2  190.0  190.0  210.0  210.0  \n",
       "3    NaN    NaN  210.0  210.0  \n",
       "4  230.0  230.0    NaN    NaN  \n",
       "5  205.0  205.0    NaN    NaN  \n",
       "6  195.0  195.0    NaN    NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_rice = parse_price_section(rice_section)\n",
    "display(df_rice.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "39b4cfba",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (4290173342.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[69], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 1ï¸âƒ£ Parse RICE section into structured DataFrame\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def parse_price_section(section_lines):\n",
    "    merged_lines = []\n",
    "    for line in section_lines:\n",
    "        if not line.strip() or \"Marandagahamula\" in line:\n",
    "            continue\n",
    "        # merge broken item lines\n",
    "        if re.match(r\"^[A-Za-z]\", line):\n",
    "            merged_lines.append(line)\n",
    "        elif merged_lines:\n",
    "            merged_lines[-1] += \" \" + line\n",
    "\n",
    "    parsed_rows = []\n",
    "\n",
    "    for line in merged_lines:\n",
    "        # clean up text\n",
    "        clean = line.replace(\",\", \"\").replace(\"â€¦\", \"\").replace(\"â€”\", \"-\")\n",
    "        clean = re.sub(r\"([a-zA-Z)])(Rs\\.)\", r\"\\1 \\2\", clean)\n",
    "        # fix glued numbers like \"130.00132.00\"\n",
    "        clean = re.sub(r\"(\\d+\\.\\d{1,2})(?=\\d+\\.\\d{1,2})\", r\"\\1 \", clean)\n",
    "\n",
    "        # tokenize text into words and numbers\n",
    "        tokens = re.findall(\n",
    "            r\"n\\.a\\.|N\\.A\\.|Rs\\.\\/[A-Za-z]+|[A-Za-z()]+|\\d+\\.\\d{1,2}|\\d+\",\n",
    "            clean,\n",
    "        )\n",
    "        if len(tokens) < 3:\n",
    "            continue\n",
    "\n",
    "        # detect Rs./kg as unit marker\n",
    "        try:\n",
    "            idx_unit = next(i for i, t in enumerate(tokens) if \"Rs\" in t)\n",
    "        except StopIteration:\n",
    "            continue\n",
    "\n",
    "        item = \" \".join(tokens[:idx_unit])\n",
    "        unit = tokens[idx_unit]\n",
    "        values = tokens[idx_unit + 1:]\n",
    "\n",
    "        split_values = []\n",
    "        for v in values:\n",
    "            nums = re.findall(r\"\\d+\\.\\d{1,2}\", v)\n",
    "            if nums:\n",
    "                split_values.extend(nums)\n",
    "            elif v.lower() == \"n.a.\":\n",
    "                split_values.append(None)\n",
    "            else:\n",
    "                split_values.append(v)\n",
    "\n",
    "        parsed_rows.append([item.strip(), unit.strip()] + split_values)\n",
    "\n",
    "    if not parsed_rows:\n",
    "        return pd.DataFrame(columns=[\"Item\", \"Unit\"])\n",
    "\n",
    "    # normalize row lengths\n",
    "    max_len = max(len(r) for r in parsed_rows)\n",
    "    for r in parsed_rows:\n",
    "        r += [None] * (max_len - len(r))\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        parsed_rows,\n",
    "        columns=[\"Item\", \"Unit\"] + [f\"Col{i}\" for i in range(1, max_len - 1)],\n",
    "    )\n",
    "\n",
    "    # cleanup columns\n",
    "    df[\"Item\"] = df[\"Item\"].str.replace(r\"Rs$\", \"\", regex=True).str.strip()\n",
    "    df[\"Unit\"] = df[\"Unit\"].str.replace(r\"[^A-Za-z/.]\", \"\", regex=True).str.strip()\n",
    "\n",
    "    # fix cases like \"Samba Rs./kg\"\n",
    "    mask = (df[\"Unit\"].eq(\"\") | df[\"Unit\"].isna()) & df[\"Item\"].str.contains(\"Rs\", na=False)\n",
    "    for i, row in df.loc[mask].iterrows():\n",
    "        match = re.search(r\"(.*?)(Rs\\.\\/[A-Za-z]+)\", row[\"Item\"])\n",
    "        if match:\n",
    "            df.at[i, \"Item\"] = match.group(1).strip()\n",
    "            df.at[i, \"Unit\"] = match.group(2).strip()\n",
    "\n",
    "    # convert to numeric\n",
    "    df = df.replace({\"n.a.\": None, \"N.A.\": None})\n",
    "    for col in df.columns[2:]:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 2ï¸âƒ£ Dynamic column name generator\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def get_dynamic_column_names(section_lines):\n",
    "    text = \" \".join(section_lines[:40]).lower()\n",
    "    columns = [\"item\", \"unit\"]\n",
    "\n",
    "    # Default locations\n",
    "    wholesale_locs = [\"pettah\"]\n",
    "    retail_locs = [\"pettah\", \"dambulla\", \"narahenpita\"]\n",
    "\n",
    "    # If Marandagahamula is mentioned, insert it right after Pettah\n",
    "    if \"marandagahamula\" in text:\n",
    "        wholesale_locs += [\"marandagahamula\"]\n",
    "\n",
    "    # # Add Dambulla *after* Marandagahamula (or Pettah if not present)\n",
    "    # wholesale_locs += [\"dambulla\"]\n",
    "\n",
    "    # Build wholesale + retail headers\n",
    "    for loc in wholesale_locs:\n",
    "        columns += [f\"wholesale_{loc}_yesterday\", f\"wholesale_{loc}_today\"]\n",
    "\n",
    "    for loc in retail_locs:\n",
    "        columns += [f\"retail_{loc}_yesterday\", f\"retail_{loc}_today\"]\n",
    "\n",
    "    return columns\n",
    "\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 3ï¸âƒ£ Combine both steps for one clean call\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def extract_and_parse_rice(pdf_path, start=\"RICE\", end=\"FISH\", page_num=2):\n",
    "    \"\"\"Extracts RICE section and returns a labeled DataFrame.\"\"\"\n",
    "    section_lines = extract_section_between(pdf_path, start, end, page_num)\n",
    "    df = parse_price_section(section_lines)\n",
    "\n",
    "    cols = get_dynamic_column_names(section_lines)\n",
    "    cols = cols[:len(df.columns)]\n",
    "    df.columns = cols\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# 4ï¸âƒ£ Example run\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "pdf_path = \"../data/raw/2023/2023-01-04.pdf\"\n",
    "df_rice = extract_and_parse_rice(pdf_path)\n",
    "\n",
    "df_rice.to_csv(\"rice_clean.csv\", index=False)\n",
    "print(\"\\nâœ… Saved to rice_clean.csv\")\n",
    "display(df_rice.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5bbc80df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… DataFrame created successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "      <th>Col5</th>\n",
       "      <th>Col6</th>\n",
       "      <th>Col7</th>\n",
       "      <th>Col8</th>\n",
       "      <th>Col9</th>\n",
       "      <th>Col10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Samba</td>\n",
       "      <td>Rs./kg</td>\n",
       "      <td>235.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nadu</td>\n",
       "      <td>Rs./kg</td>\n",
       "      <td>220.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>225.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>230.0</td>\n",
       "      <td>230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kekulu (White)</td>\n",
       "      <td>Rs./kg</td>\n",
       "      <td>215.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>225.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kekulu (Red)</td>\n",
       "      <td>Rs./kg</td>\n",
       "      <td>215.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>220.0</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ponni Samba (Imp)</td>\n",
       "      <td>Rs./kg</td>\n",
       "      <td>228.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nadu (Imp)</td>\n",
       "      <td>Rs./kg</td>\n",
       "      <td>220.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>230.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kekulu (White) (Imp)</td>\n",
       "      <td>Rs./kg</td>\n",
       "      <td>215.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>230.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>220.0</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Item    Unit   Col1   Col2   Col3   Col4   Col5   Col6  \\\n",
       "0                 Samba  Rs./kg  235.0  235.0  239.0  239.0    NaN    NaN   \n",
       "1                  Nadu  Rs./kg  220.0  220.0  229.0  229.0    NaN    NaN   \n",
       "2        Kekulu (White)  Rs./kg  215.0  215.0  217.0  217.0    NaN    NaN   \n",
       "3          Kekulu (Red)  Rs./kg  215.0  215.0    NaN    NaN    NaN    NaN   \n",
       "4     Ponni Samba (Imp)  Rs./kg  228.0  228.0    NaN    NaN  240.0  240.0   \n",
       "5            Nadu (Imp)  Rs./kg  220.0  220.0    NaN    NaN  230.0  230.0   \n",
       "6  Kekulu (White) (Imp)  Rs./kg  215.0  213.0    NaN    NaN  230.0  230.0   \n",
       "\n",
       "    Col7   Col8   Col9  Col10  \n",
       "0  240.0  240.0  240.0  240.0  \n",
       "1  225.0    NaN  230.0  230.0  \n",
       "2  225.0    NaN    NaN    NaN  \n",
       "3    NaN    NaN  220.0  220.0  \n",
       "4    NaN    NaN  240.0  240.0  \n",
       "5    NaN    NaN    NaN    NaN  \n",
       "6    NaN    NaN  220.0  220.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Helper: pad missing middle columns intelligently\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def normalize_price_row(values, expected=10, pad_index=6):\n",
    "    \"\"\"\n",
    "    Ensures consistent number of numeric slots per row.\n",
    "    Pads missing Nones *after the wholesale group* (default index = 6).\n",
    "    This aligns missing retail columns correctly.\n",
    "    \"\"\"\n",
    "    values = list(values)\n",
    "    if len(values) < expected:\n",
    "        diff = expected - len(values)\n",
    "        insert_at = min(pad_index, len(values))\n",
    "        values[insert_at:insert_at] = [None] * diff\n",
    "    return values\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Main parser\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def parse_price_section(section_lines):\n",
    "    \"\"\"\n",
    "    Convert a price section (e.g., 'RICE') into a clean structured DataFrame.\n",
    "    Handles broken lines, glued numbers, and invisible column gaps.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: merge broken lines\n",
    "    merged_lines = []\n",
    "    for line in section_lines:\n",
    "        if not line.strip() or \"Marandagahamula\" in line:\n",
    "            continue\n",
    "\n",
    "        # if starts with a letter, it's a new row\n",
    "        if re.match(r\"^[A-Za-z]\", line):\n",
    "            merged_lines.append(line)\n",
    "        elif merged_lines:\n",
    "            merged_lines[-1] += \" \" + line  # continuation of previous item\n",
    "\n",
    "    parsed_rows = []\n",
    "\n",
    "    # Step 2: clean and tokenize each line\n",
    "    for line in merged_lines:\n",
    "        clean = (\n",
    "            line.replace(\",\", \"\")\n",
    "                .replace(\"...\", \"\")\n",
    "                .replace(\"â€”\", \"-\")\n",
    "        )\n",
    "        clean = re.sub(r\"([a-zA-Z)])(Rs\\.)\", r\"\\1 \\2\", clean)\n",
    "        clean = re.sub(r\"(\\d+\\.\\d{1,2})(?=\\d+\\.\\d{1,2})\", r\"\\1 \", clean)\n",
    "\n",
    "        tokens = re.findall(\n",
    "            r\"n\\.a\\.|N\\.A\\.|Rs\\.\\/[A-Za-z]+|[A-Za-z()]+|\\d+\\.\\d{1,2}|\\d+\",\n",
    "            clean\n",
    "        )\n",
    "        if len(tokens) < 3:\n",
    "            continue\n",
    "\n",
    "        # find Rs./kg or Rs./Ltr as the unit marker\n",
    "        try:\n",
    "            idx_unit = next(i for i, t in enumerate(tokens) if \"Rs\" in t)\n",
    "        except StopIteration:\n",
    "            continue\n",
    "\n",
    "        item = \" \".join(tokens[:idx_unit]).strip()\n",
    "        unit = tokens[idx_unit].strip()\n",
    "        values = tokens[idx_unit + 1:]\n",
    "\n",
    "        # Step 3: extract numbers and mark blanks\n",
    "        split_values = []\n",
    "        for v in values:\n",
    "            nums = re.findall(r\"\\d+\\.\\d{1,2}\", v)\n",
    "            if nums:\n",
    "                split_values.extend(nums)\n",
    "            elif v.lower() == \"n.a.\":\n",
    "                split_values.append(None)\n",
    "            else:\n",
    "                split_values.append(None)\n",
    "\n",
    "        # Step 4: pad missing mid columns (expected 10 cols, pad after col 6)\n",
    "        split_values = normalize_price_row(split_values, expected=10, pad_index=6)\n",
    "\n",
    "        parsed_rows.append([item, unit] + split_values)\n",
    "\n",
    "    # Step 5: build DataFrame\n",
    "    if not parsed_rows:\n",
    "        return pd.DataFrame(columns=[\"Item\", \"Unit\"])\n",
    "\n",
    "    max_len = max(len(r) for r in parsed_rows)\n",
    "    for r in parsed_rows:\n",
    "        r += [None] * (max_len - len(r))\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        parsed_rows,\n",
    "        columns=[\"Item\", \"Unit\"] + [f\"Col{i}\" for i in range(1, max_len - 1)]\n",
    "    )\n",
    "\n",
    "    # Step 6: cleanup units and items\n",
    "    df[\"Item\"] = df[\"Item\"].str.replace(r\"Rs$\", \"\", regex=True).str.strip()\n",
    "    df[\"Unit\"] = df[\"Unit\"].str.replace(r\"[^A-Za-z/.]\", \"\", regex=True).str.strip()\n",
    "\n",
    "    # fix cases where Rs is stuck in Item\n",
    "    mask = (df[\"Unit\"].eq(\"\") | df[\"Unit\"].isna()) & df[\"Item\"].str.contains(\"Rs\", na=False)\n",
    "    for i, row in df.loc[mask].iterrows():\n",
    "        match = re.search(r\"(.*?)(Rs\\.\\/[A-Za-z]+)\", row[\"Item\"])\n",
    "        if match:\n",
    "            df.at[i, \"Item\"] = match.group(1).strip()\n",
    "            df.at[i, \"Unit\"] = match.group(2).strip()\n",
    "\n",
    "    # Step 7: convert prices to numeric\n",
    "    df = df.replace({\"n.a.\": None, \"N.A.\": None})\n",
    "    for col in df.columns[2:]:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # âœ… Step 8: Return DataFrame\n",
    "    return df\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Extract + parse function\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def extract_and_parse_rice(pdf_path, start=\"RICE\", end=\"FISH\", page_num=2):\n",
    "    \"\"\"Extracts RICE section and parses into a DataFrame.\"\"\"\n",
    "    section_lines = extract_section_between(pdf_path, start, end, page_num)\n",
    "    df = parse_price_section(section_lines)\n",
    "    return df\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Example run\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "pdf_path = \"../data/raw/2025/2025-01-03.pdf\"\n",
    "df_rice = extract_and_parse_rice(pdf_path)\n",
    "\n",
    "print(\"\\nâœ… DataFrame created successfully!\")\n",
    "display(df_rice.head(10))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b4879630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXAMPLE 2: Parsing from PDF\n",
      "============================================================\n",
      "\n",
      "âœ… DataFrame created successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Col1</th>\n",
       "      <th>Col2</th>\n",
       "      <th>Col3</th>\n",
       "      <th>Col4</th>\n",
       "      <th>Col5</th>\n",
       "      <th>Col6</th>\n",
       "      <th>Col7</th>\n",
       "      <th>Col8</th>\n",
       "      <th>Col9</th>\n",
       "      <th>Col10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Samba</td>\n",
       "      <td>Rs./kg</td>\n",
       "      <td>235.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nadu</td>\n",
       "      <td>Rs./kg</td>\n",
       "      <td>220.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>225.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>230.0</td>\n",
       "      <td>230.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kekulu (White)</td>\n",
       "      <td>Rs./kg</td>\n",
       "      <td>215.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>225.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kekulu (Red)</td>\n",
       "      <td>Rs./kg</td>\n",
       "      <td>215.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>220.0</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ponni Samba (Imp)</td>\n",
       "      <td>Rs./kg</td>\n",
       "      <td>228.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240.0</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nadu (Imp)</td>\n",
       "      <td>Rs./kg</td>\n",
       "      <td>220.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>230.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kekulu (White) (Imp)</td>\n",
       "      <td>Rs./kg</td>\n",
       "      <td>215.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>230.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>220.0</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Item    Unit   Col1   Col2   Col3   Col4   Col5   Col6  \\\n",
       "0                 Samba  Rs./kg  235.0  235.0  239.0  239.0    NaN    NaN   \n",
       "1                  Nadu  Rs./kg  220.0  220.0  229.0  229.0    NaN    NaN   \n",
       "2        Kekulu (White)  Rs./kg  215.0  215.0  217.0  217.0    NaN    NaN   \n",
       "3          Kekulu (Red)  Rs./kg  215.0  215.0    NaN    NaN    NaN    NaN   \n",
       "4     Ponni Samba (Imp)  Rs./kg  228.0  228.0    NaN    NaN  240.0  240.0   \n",
       "5            Nadu (Imp)  Rs./kg  220.0  220.0    NaN    NaN  230.0  230.0   \n",
       "6  Kekulu (White) (Imp)  Rs./kg  215.0  213.0    NaN    NaN  230.0  230.0   \n",
       "\n",
       "    Col7   Col8   Col9  Col10  \n",
       "0  240.0  240.0  240.0  240.0  \n",
       "1  225.0    NaN  230.0  230.0  \n",
       "2  225.0    NaN    NaN    NaN  \n",
       "3    NaN    NaN  220.0  220.0  \n",
       "4    NaN    NaN  240.0  240.0  \n",
       "5    NaN    NaN    NaN    NaN  \n",
       "6    NaN    NaN  220.0  220.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# PART 1: Helper Function - Fix Missing Columns\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def fix_missing_columns(price_list, total_columns=10, insert_position=6):\n",
    "    \"\"\"\n",
    "    Makes sure each row has the same number of price columns.\n",
    "    \n",
    "    Why? Sometimes data has missing columns in the middle (like missing retail prices).\n",
    "    We need to add empty spaces (None) in the right place.\n",
    "    \n",
    "    Example:\n",
    "        Input:  [130.00, 132.00, 135.00]  (only 3 prices, but we need 10)\n",
    "        Output: [130.00, 132.00, 135.00, None, None, None, None, None, None, None]\n",
    "        \n",
    "        The None values are added after position 6 (after wholesale prices).\n",
    "    \n",
    "    Parameters:\n",
    "        price_list: List of prices (may be incomplete)\n",
    "        total_columns: How many columns we want in total (default: 10)\n",
    "        insert_position: Where to add missing values (default: 6)\n",
    "    \n",
    "    Returns:\n",
    "        A list with exactly 'total_columns' items\n",
    "    \"\"\"\n",
    "    # Make a copy so we don't change the original\n",
    "    price_list = list(price_list)\n",
    "    \n",
    "    # Check if we're missing columns\n",
    "    if len(price_list) < total_columns:\n",
    "        # Calculate how many columns are missing\n",
    "        missing_count = total_columns - len(price_list)\n",
    "        \n",
    "        # Don't insert beyond what we have\n",
    "        safe_position = min(insert_position, len(price_list))\n",
    "        \n",
    "        # Insert None values at the right position\n",
    "        # This is like cutting the list and inserting empty spaces\n",
    "        for i in range(missing_count):\n",
    "            price_list.insert(safe_position, None)\n",
    "    \n",
    "    return price_list\n",
    "\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# PART 2: Main Parser - Convert Messy Text to Clean Table\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def parse_price_section(section_lines):\n",
    "    \"\"\"\n",
    "    Takes messy price text and creates a neat table (DataFrame).\n",
    "    \n",
    "    What it does:\n",
    "        1. Combines broken lines\n",
    "        2. Cleans up the text\n",
    "        3. Splits each line into: Item name, Unit, and Prices\n",
    "        4. Creates a table with all the data\n",
    "    \n",
    "    Input example:\n",
    "        [\"Samba Rs./kg 130.00 132.00 135.00\",\n",
    "         \"Nadu (White)\",\n",
    "         \"Rs./kg 125.00 128.00\"]\n",
    "    \n",
    "    Output: A pandas table with columns [Item, Unit, Col1, Col2, ...]\n",
    "    \"\"\"\n",
    "    \n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # STEP 1: Combine Lines That Belong Together\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # Sometimes one item is split across multiple lines. We fix that here.\n",
    "    \n",
    "    merged_lines = []\n",
    "    \n",
    "    for line in section_lines:\n",
    "        # Skip empty lines or lines with \"Marandagahamula\"\n",
    "        if not line.strip() or \"Marandagahamula\" in line:\n",
    "            continue\n",
    "        \n",
    "        # Does this line start with a letter? Then it's a NEW item\n",
    "        if re.match(r\"^[A-Za-z]\", line):\n",
    "            merged_lines.append(line)\n",
    "        \n",
    "        # Otherwise, add it to the PREVIOUS item\n",
    "        elif len(merged_lines) > 0:\n",
    "            merged_lines[-1] = merged_lines[-1] + \" \" + line\n",
    "    \n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # STEP 2: Process Each Line\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    \n",
    "    parsed_rows = []  # Will store all our cleaned data\n",
    "    \n",
    "    for line in merged_lines:\n",
    "        \n",
    "        # â”€â”€â”€ Clean up the text â”€â”€â”€\n",
    "        clean_line = line\n",
    "        clean_line = clean_line.replace(\",\", \"\")      # Remove commas\n",
    "        clean_line = clean_line.replace(\"...\", \"\")    # Remove dots\n",
    "        clean_line = clean_line.replace(\"â€”\", \"-\")     # Fix dashes\n",
    "        \n",
    "        # Add space between letters and \"Rs.\"\n",
    "        # \"SambaRs.\" becomes \"Samba Rs.\"\n",
    "        clean_line = re.sub(r\"([a-zA-Z)])(Rs\\.)\", r\"\\1 \\2\", clean_line)\n",
    "        \n",
    "        # Separate numbers that are stuck together\n",
    "        # \"130.00132.00\" becomes \"130.00 132.00\"\n",
    "        clean_line = re.sub(r\"(\\d+\\.\\d{1,2})(?=\\d+\\.\\d{1,2})\", r\"\\1 \", clean_line)\n",
    "        \n",
    "        # â”€â”€â”€ Break line into pieces (tokens) â”€â”€â”€\n",
    "        # Find: \"n.a.\", \"Rs./kg\", words, and decimal numbers\n",
    "        tokens = re.findall(\n",
    "            r\"n\\.a\\.|N\\.A\\.|Rs\\.\\/[A-Za-z]+|[A-Za-z()]+|\\d+\\.\\d{1,2}|\\d+\",\n",
    "            clean_line\n",
    "        )\n",
    "        \n",
    "        # Need at least 3 pieces (item name, unit, one price)\n",
    "        if len(tokens) < 3:\n",
    "            continue  # Skip this line, not enough data\n",
    "        \n",
    "        # â”€â”€â”€ Find the unit marker (Rs./kg or Rs./Ltr) â”€â”€â”€\n",
    "        unit_index = None\n",
    "        for i, token in enumerate(tokens):\n",
    "            if \"Rs\" in token:\n",
    "                unit_index = i\n",
    "                break\n",
    "        \n",
    "        # If no unit found, skip this line\n",
    "        if unit_index is None:\n",
    "            continue\n",
    "        \n",
    "        # â”€â”€â”€ Split tokens into parts â”€â”€â”€\n",
    "        item_name = \" \".join(tokens[:unit_index]).strip()  # Everything before \"Rs./kg\"\n",
    "        unit = tokens[unit_index].strip()                  # \"Rs./kg\"\n",
    "        value_tokens = tokens[unit_index + 1:]             # All prices after unit\n",
    "        \n",
    "        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        # STEP 3: Extract Price Numbers\n",
    "        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        \n",
    "        prices = []\n",
    "        for value in value_tokens:\n",
    "            # Find decimal numbers in this token\n",
    "            numbers = re.findall(r\"\\d+\\.\\d{1,2}\", value)\n",
    "            \n",
    "            if numbers:\n",
    "                # Add all numbers found\n",
    "                prices.extend(numbers)\n",
    "            elif value.lower() == \"n.a.\":\n",
    "                # \"n.a.\" means missing data\n",
    "                prices.append(None)\n",
    "            else:\n",
    "                # Unknown value, treat as missing\n",
    "                prices.append(None)\n",
    "        \n",
    "        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        # STEP 4: Fix Missing Columns\n",
    "        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        # Make sure we have exactly 10 price columns\n",
    "        # Missing columns are added after position 6\n",
    "        \n",
    "        prices = fix_missing_columns(prices, total_columns=10, insert_position=6)\n",
    "        \n",
    "        # â”€â”€â”€ Create row: [Item, Unit, Price1, Price2, ...] â”€â”€â”€\n",
    "        row = [item_name, unit] + prices\n",
    "        parsed_rows.append(row)\n",
    "    \n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # STEP 5: Create the DataFrame (Table)\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    \n",
    "    # If no data was found, return an empty table\n",
    "    if len(parsed_rows) == 0:\n",
    "        return pd.DataFrame(columns=[\"Item\", \"Unit\"])\n",
    "    \n",
    "    # Find the longest row\n",
    "    max_length = max(len(row) for row in parsed_rows)\n",
    "    \n",
    "    # Make all rows the same length by adding None to the end\n",
    "    for row in parsed_rows:\n",
    "        while len(row) < max_length:\n",
    "            row.append(None)\n",
    "    \n",
    "    # Create column names: Item, Unit, Col1, Col2, Col3...\n",
    "    num_price_cols = max_length - 2\n",
    "    column_names = [\"Item\", \"Unit\"] + [f\"Col{i}\" for i in range(1, num_price_cols + 1)]\n",
    "    \n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame(parsed_rows, columns=column_names)\n",
    "    \n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # STEP 6: Clean Up Item Names and Units\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    \n",
    "    # Remove \"Rs\" from end of item names\n",
    "    df[\"Item\"] = df[\"Item\"].str.replace(r\"Rs$\", \"\", regex=True).str.strip()\n",
    "    \n",
    "    # Clean unit column (keep only letters, slash, dot)\n",
    "    df[\"Unit\"] = df[\"Unit\"].str.replace(r\"[^A-Za-z/.]\", \"\", regex=True).str.strip()\n",
    "    \n",
    "    # Fix cases where \"Rs./kg\" ended up in the Item column\n",
    "    # Example: \"Samba Rs./kg\" should be split into \"Samba\" | \"Rs./kg\"\n",
    "    \n",
    "    # Find rows where Unit is empty but Item contains \"Rs\"\n",
    "    has_problem = (df[\"Unit\"] == \"\") | (df[\"Unit\"].isna())\n",
    "    has_problem = has_problem & df[\"Item\"].str.contains(\"Rs\", na=False)\n",
    "    \n",
    "    for index in df[has_problem].index:\n",
    "        item_text = df.at[index, \"Item\"]\n",
    "        \n",
    "        # Try to split \"Samba Rs./kg\" into two parts\n",
    "        match = re.search(r\"(.*?)(Rs\\.\\/[A-Za-z]+)\", item_text)\n",
    "        if match:\n",
    "            df.at[index, \"Item\"] = match.group(1).strip()  # \"Samba\"\n",
    "            df.at[index, \"Unit\"] = match.group(2).strip()  # \"Rs./kg\"\n",
    "    \n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # STEP 7: Convert Prices to Numbers\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    \n",
    "    # Replace text \"n.a.\" with actual None (missing value)\n",
    "    df = df.replace({\"n.a.\": None, \"N.A.\": None})\n",
    "    \n",
    "    # Convert all price columns from text to numbers\n",
    "    for col in df.columns[2:]:  # Skip Item and Unit columns\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    \n",
    "    # âœ… Done! Return the clean table\n",
    "    return df\n",
    "\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# PART 3: Extract Section from PDF and Parse It\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def extract_and_parse_rice(pdf_path, start_word=\"RICE\", end_word=\"FISH\", page_number=2):\n",
    "    \"\"\"\n",
    "    Extracts the RICE section from a PDF and converts it to a table.\n",
    "    \n",
    "    This function does two things:\n",
    "        1. Finds and extracts text between \"RICE\" and \"FISH\" in the PDF\n",
    "        2. Parses that text into a clean DataFrame\n",
    "    \n",
    "    Parameters:\n",
    "        pdf_path: Path to the PDF file\n",
    "        start_word: Word that marks the beginning of the section (default: \"RICE\")\n",
    "        end_word: Word that marks the end of the section (default: \"FISH\")\n",
    "        page_number: Which page to look at (default: 2)\n",
    "    \n",
    "    Returns:\n",
    "        A pandas DataFrame with the parsed price data\n",
    "    \"\"\"\n",
    "    \n",
    "    # NOTE: You need to define extract_section_between() function\n",
    "    # That function should read the PDF and return lines of text\n",
    "    section_lines = extract_section_between(pdf_path, start_word, end_word, page_number)\n",
    "    \n",
    "    # Parse the extracted lines into a DataFrame\n",
    "    df = parse_price_section(section_lines)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# PART 4: Example Usage (How to Run This Code)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # # Example 1: Test with sample data (no PDF needed)\n",
    "    # print(\"=\" * 60)\n",
    "    # print(\"EXAMPLE 1: Testing with sample data\")\n",
    "    # print(\"=\" * 60)\n",
    "    \n",
    "    # sample_lines = [\n",
    "    #     \"Samba Rs./kg 130.00 132.00 135.00 140.00\",\n",
    "    #     \"Nadu (White)\",\n",
    "    #     \"Rs./kg 125.00 128.00 130.00\",\n",
    "    #     \"Red Nadu Rs./kg 120.00 122.00 n.a. 125.00\",\n",
    "    #     \"Keeri Samba Rs./kg 140.00 145.00 150.00 155.00 160.00\"\n",
    "    # ]\n",
    "    \n",
    "    # result = parse_price_section(sample_lines)\n",
    "    # print(\"\\nğŸ“Š Parsed Table:\")\n",
    "    # print(result)\n",
    "    # print(\"\\nğŸ“‹ Column Types:\")\n",
    "    # print(result.dtypes)\n",
    "    \n",
    "    # Example 2: Parse from actual PDF (uncomment to use)\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"EXAMPLE 2: Parsing from PDF\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    pdf_path = \"../data/raw/2025/2025-01-03.pdf\"\n",
    "    df_rice = extract_and_parse_rice(pdf_path)\n",
    "    \n",
    "    print(\"\\nâœ… DataFrame created successfully!\")\n",
    "    display(df_rice.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0b2f1f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXAMPLE 3: Parsing from PDF with smart columns\n",
      "============================================================\n",
      "\n",
      "âœ… DataFrame created successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>unit</th>\n",
       "      <th>wholesale_pettah_yesterday</th>\n",
       "      <th>wholesale_pettah_today</th>\n",
       "      <th>wholesale_marandagahamula_yesterday</th>\n",
       "      <th>wholesale_marandagahamula_today</th>\n",
       "      <th>retail_pettah_yesterday</th>\n",
       "      <th>retail_pettah_today</th>\n",
       "      <th>retail_dambulla_yesterday</th>\n",
       "      <th>retail_dambulla_today</th>\n",
       "      <th>retail_narahenpita_yesterday</th>\n",
       "      <th>retail_narahenpita_today</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Samba</td>\n",
       "      <td>Rs./kg</td>\n",
       "      <td>235.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nadu</td>\n",
       "      <td>Rs./kg</td>\n",
       "      <td>210.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kekulu (White)</td>\n",
       "      <td>Rs./kg</td>\n",
       "      <td>202.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kekulu (Red)</td>\n",
       "      <td>Rs./kg</td>\n",
       "      <td>180.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ponni Samba (Imp)</td>\n",
       "      <td>Rs./kg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nadu (Imp)</td>\n",
       "      <td>Rs./kgn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kekulu (White) (Imp)</td>\n",
       "      <td>Rs./kgn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   item     unit  wholesale_pettah_yesterday  \\\n",
       "0                 Samba   Rs./kg                       235.0   \n",
       "1                  Nadu   Rs./kg                       210.0   \n",
       "2        Kekulu (White)   Rs./kg                       202.0   \n",
       "3          Kekulu (Red)   Rs./kg                       180.0   \n",
       "4     Ponni Samba (Imp)   Rs./kg                         NaN   \n",
       "5            Nadu (Imp)  Rs./kgn                         NaN   \n",
       "6  Kekulu (White) (Imp)  Rs./kgn                         NaN   \n",
       "\n",
       "   wholesale_pettah_today  wholesale_marandagahamula_yesterday  \\\n",
       "0                   235.0                                231.0   \n",
       "1                   210.0                                203.0   \n",
       "2                   202.0                                197.0   \n",
       "3                   180.0                                188.0   \n",
       "4                     NaN                                  NaN   \n",
       "5                     NaN                                  NaN   \n",
       "6                     NaN                                  NaN   \n",
       "\n",
       "   wholesale_marandagahamula_today  retail_pettah_yesterday  \\\n",
       "0                            231.0                    250.0   \n",
       "1                            203.0                    220.0   \n",
       "2                            197.0                    210.0   \n",
       "3                            187.0                    200.0   \n",
       "4                              NaN                      NaN   \n",
       "5                              NaN                      NaN   \n",
       "6                              NaN                      NaN   \n",
       "\n",
       "   retail_pettah_today  retail_dambulla_yesterday  retail_dambulla_today  \\\n",
       "0                250.0                      242.0                  242.0   \n",
       "1                220.0                      205.0                  214.0   \n",
       "2                210.0                      197.0                  192.0   \n",
       "3                200.0                      192.0                  182.0   \n",
       "4                  NaN                        NaN                    NaN   \n",
       "5                  NaN                        NaN                    NaN   \n",
       "6                  NaN                        NaN                    NaN   \n",
       "\n",
       "   retail_narahenpita_yesterday  retail_narahenpita_today  \n",
       "0                           NaN                       NaN  \n",
       "1                         220.0                     220.0  \n",
       "2                         210.0                     210.0  \n",
       "3                         195.0                     195.0  \n",
       "4                           NaN                       NaN  \n",
       "5                           NaN                       NaN  \n",
       "6                           NaN                       NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“‹ Column Names:\n",
      "['item', 'unit', 'wholesale_pettah_yesterday', 'wholesale_pettah_today', 'wholesale_marandagahamula_yesterday', 'wholesale_marandagahamula_today', 'retail_pettah_yesterday', 'retail_pettah_today', 'retail_dambulla_yesterday', 'retail_dambulla_today', 'retail_narahenpita_yesterday', 'retail_narahenpita_today']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# PART 1: Helper Function - Fix Missing Columns\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def fix_missing_columns(price_list, total_columns=10, insert_position=6):\n",
    "    \"\"\"\n",
    "    Makes sure each row has the same number of price columns.\n",
    "    \n",
    "    Why? Sometimes data has missing columns in the middle (like missing retail prices).\n",
    "    We need to add empty spaces (None) in the right place.\n",
    "    \n",
    "    Example:\n",
    "        Input:  [130.00, 132.00, 135.00]  (only 3 prices, but we need 10)\n",
    "        Output: [130.00, 132.00, 135.00, None, None, None, None, None, None, None]\n",
    "        \n",
    "        The None values are added after position 6 (after wholesale prices).\n",
    "    \n",
    "    Parameters:\n",
    "        price_list: List of prices (may be incomplete)\n",
    "        total_columns: How many columns we want in total (default: 10)\n",
    "        insert_position: Where to add missing values (default: 6)\n",
    "    \n",
    "    Returns:\n",
    "        A list with exactly 'total_columns' items\n",
    "    \"\"\"\n",
    "    # Make a copy so we don't change the original\n",
    "    price_list = list(price_list)\n",
    "    \n",
    "    # Check if we're missing columns\n",
    "    if len(price_list) < total_columns:\n",
    "        # Calculate how many columns are missing\n",
    "        missing_count = total_columns - len(price_list)\n",
    "        \n",
    "        # Don't insert beyond what we have\n",
    "        safe_position = min(insert_position, len(price_list))\n",
    "        \n",
    "        # Insert None values at the right position\n",
    "        # This is like cutting the list and inserting empty spaces\n",
    "        for i in range(missing_count):\n",
    "            price_list.insert(safe_position, None)\n",
    "    \n",
    "    return price_list\n",
    "\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# PART 2: Main Parser - Convert Messy Text to Clean Table\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def parse_price_section(section_lines):\n",
    "    \"\"\"\n",
    "    Takes messy price text and creates a neat table (DataFrame).\n",
    "    \n",
    "    What it does:\n",
    "        1. Combines broken lines\n",
    "        2. Cleans up the text\n",
    "        3. Splits each line into: Item name, Unit, and Prices\n",
    "        4. Creates a table with all the data\n",
    "    \n",
    "    Input example:\n",
    "        [\"Samba Rs./kg 130.00 132.00 135.00\",\n",
    "         \"Nadu (White)\",\n",
    "         \"Rs./kg 125.00 128.00\"]\n",
    "    \n",
    "    Output: A pandas table with columns [Item, Unit, Col1, Col2, ...]\n",
    "    \"\"\"\n",
    "    \n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # STEP 1: Combine Lines That Belong Together\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # Sometimes one item is split across multiple lines. We fix that here.\n",
    "    \n",
    "    merged_lines = []\n",
    "    \n",
    "    for line in section_lines:\n",
    "        # Skip empty lines or lines with \"Marandagahamula\"\n",
    "        if not line.strip() or \"Marandagahamula\" in line:\n",
    "            continue\n",
    "        \n",
    "        # Does this line start with a letter? Then it's a NEW item\n",
    "        if re.match(r\"^[A-Za-z]\", line):\n",
    "            merged_lines.append(line)\n",
    "        \n",
    "        # Otherwise, add it to the PREVIOUS item\n",
    "        elif len(merged_lines) > 0:\n",
    "            merged_lines[-1] = merged_lines[-1] + \" \" + line\n",
    "    \n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # STEP 2: Process Each Line\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    \n",
    "    parsed_rows = []  # Will store all our cleaned data\n",
    "    \n",
    "    for line in merged_lines:\n",
    "        \n",
    "        # â”€â”€â”€ Clean up the text â”€â”€â”€\n",
    "        clean_line = line\n",
    "        clean_line = clean_line.replace(\",\", \"\")      # Remove commas\n",
    "        clean_line = clean_line.replace(\"...\", \"\")    # Remove dots\n",
    "        clean_line = clean_line.replace(\"â€”\", \"-\")     # Fix dashes\n",
    "        \n",
    "        # Add space between letters and \"Rs.\"\n",
    "        # \"SambaRs.\" becomes \"Samba Rs.\"\n",
    "        clean_line = re.sub(r\"([a-zA-Z)])(Rs\\.)\", r\"\\1 \\2\", clean_line)\n",
    "        \n",
    "        # Separate numbers that are stuck together\n",
    "        # \"130.00132.00\" becomes \"130.00 132.00\"\n",
    "        clean_line = re.sub(r\"(\\d+\\.\\d{1,2})(?=\\d+\\.\\d{1,2})\", r\"\\1 \", clean_line)\n",
    "        \n",
    "        # â”€â”€â”€ Break line into pieces (tokens) â”€â”€â”€\n",
    "        # Find: \"n.a.\", \"Rs./kg\", words, and decimal numbers\n",
    "        tokens = re.findall(\n",
    "            r\"n\\.a\\.|N\\.A\\.|Rs\\.\\/[A-Za-z]+|[A-Za-z()]+|\\d+\\.\\d{1,2}|\\d+\",\n",
    "            clean_line\n",
    "        )\n",
    "        \n",
    "        # Need at least 3 pieces (item name, unit, one price)\n",
    "        if len(tokens) < 3:\n",
    "            continue  # Skip this line, not enough data\n",
    "        \n",
    "        # â”€â”€â”€ Find the unit marker (Rs./kg or Rs./Ltr) â”€â”€â”€\n",
    "        unit_index = None\n",
    "        for i, token in enumerate(tokens):\n",
    "            if \"Rs\" in token:\n",
    "                unit_index = i\n",
    "                break\n",
    "        \n",
    "        # If no unit found, skip this line\n",
    "        if unit_index is None:\n",
    "            continue\n",
    "        \n",
    "        # â”€â”€â”€ Split tokens into parts â”€â”€â”€\n",
    "        item_name = \" \".join(tokens[:unit_index]).strip()  # Everything before \"Rs./kg\"\n",
    "        unit = tokens[unit_index].strip()                  # \"Rs./kg\"\n",
    "        value_tokens = tokens[unit_index + 1:]             # All prices after unit\n",
    "        \n",
    "        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        # STEP 3: Extract Price Numbers\n",
    "        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        \n",
    "        prices = []\n",
    "        for value in value_tokens:\n",
    "            # Find decimal numbers in this token\n",
    "            numbers = re.findall(r\"\\d+\\.\\d{1,2}\", value)\n",
    "            \n",
    "            if numbers:\n",
    "                # Add all numbers found\n",
    "                prices.extend(numbers)\n",
    "            elif value.lower() == \"n.a.\":\n",
    "                # \"n.a.\" means missing data\n",
    "                prices.append(None)\n",
    "            else:\n",
    "                # Unknown value, treat as missing\n",
    "                prices.append(None)\n",
    "        \n",
    "        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        # STEP 4: Fix Missing Columns\n",
    "        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        # Make sure we have exactly 10 price columns\n",
    "        # Missing columns are added after position 6\n",
    "        \n",
    "        prices = fix_missing_columns(prices, total_columns=10, insert_position=6)\n",
    "        \n",
    "        # â”€â”€â”€ Create row: [Item, Unit, Price1, Price2, ...] â”€â”€â”€\n",
    "        row = [item_name, unit] + prices\n",
    "        parsed_rows.append(row)\n",
    "    \n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # STEP 5: Create the DataFrame (Table)\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    \n",
    "    # If no data was found, return an empty table\n",
    "    if len(parsed_rows) == 0:\n",
    "        return pd.DataFrame(columns=[\"Item\", \"Unit\"])\n",
    "    \n",
    "    # Find the longest row\n",
    "    max_length = max(len(row) for row in parsed_rows)\n",
    "    \n",
    "    # Make all rows the same length by adding None to the end\n",
    "    for row in parsed_rows:\n",
    "        while len(row) < max_length:\n",
    "            row.append(None)\n",
    "    \n",
    "    # Create column names: Item, Unit, Col1, Col2, Col3...\n",
    "    num_price_cols = max_length - 2\n",
    "    column_names = [\"Item\", \"Unit\"] + [f\"Col{i}\" for i in range(1, num_price_cols + 1)]\n",
    "    \n",
    "    # Create the DataFrame\n",
    "    df = pd.DataFrame(parsed_rows, columns=column_names)\n",
    "    \n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # STEP 6: Clean Up Item Names and Units\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    \n",
    "    # Remove \"Rs\" from end of item names\n",
    "    df[\"Item\"] = df[\"Item\"].str.replace(r\"Rs$\", \"\", regex=True).str.strip()\n",
    "    \n",
    "    # Clean unit column (keep only letters, slash, dot)\n",
    "    df[\"Unit\"] = df[\"Unit\"].str.replace(r\"[^A-Za-z/.]\", \"\", regex=True).str.strip()\n",
    "    \n",
    "    # Fix cases where \"Rs./kg\" ended up in the Item column\n",
    "    # Example: \"Samba Rs./kg\" should be split into \"Samba\" | \"Rs./kg\"\n",
    "    \n",
    "    # Find rows where Unit is empty but Item contains \"Rs\"\n",
    "    has_problem = (df[\"Unit\"] == \"\") | (df[\"Unit\"].isna())\n",
    "    has_problem = has_problem & df[\"Item\"].str.contains(\"Rs\", na=False)\n",
    "    \n",
    "    for index in df[has_problem].index:\n",
    "        item_text = df.at[index, \"Item\"]\n",
    "        \n",
    "        # Try to split \"Samba Rs./kg\" into two parts\n",
    "        match = re.search(r\"(.*?)(Rs\\.\\/[A-Za-z]+)\", item_text)\n",
    "        if match:\n",
    "            df.at[index, \"Item\"] = match.group(1).strip()  # \"Samba\"\n",
    "            df.at[index, \"Unit\"] = match.group(2).strip()  # \"Rs./kg\"\n",
    "    \n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # STEP 7: Convert Prices to Numbers\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    \n",
    "    # Replace text \"n.a.\" with actual None (missing value)\n",
    "    df = df.replace({\"n.a.\": None, \"N.A.\": None})\n",
    "    \n",
    "    # Convert all price columns from text to numbers\n",
    "    for col in df.columns[2:]:  # Skip Item and Unit columns\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    \n",
    "    # âœ… Done! Return the clean table\n",
    "    return df\n",
    "\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# PART 3: Smart Column Names (Detects Locations Automatically)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def create_smart_column_names(section_lines):\n",
    "    \"\"\"\n",
    "    Creates meaningful column names based on what locations are in the data.\n",
    "    \n",
    "    Why? The data has prices from different markets and different days.\n",
    "    Instead of \"Col1, Col2, Col3...\", we want names like:\n",
    "        \"wholesale_pettah_yesterday\", \"wholesale_pettah_today\", etc.\n",
    "    \n",
    "    How it works:\n",
    "        1. Looks at the first 50 lines to see what locations are mentioned\n",
    "        2. Checks if \"Marandagahamula\" market exists\n",
    "        3. Creates column names for each location and day\n",
    "    \n",
    "    Typical structure:\n",
    "        - Wholesale markets: Pettah, Dambulla (sometimes Marandagahamula)\n",
    "        - Retail markets: Pettah, Dambulla, Narahenpita\n",
    "        - Each location has: Yesterday's price + Today's price\n",
    "    \n",
    "    Parameters:\n",
    "        section_lines: List of text lines from the document\n",
    "    \n",
    "    Returns:\n",
    "        List of column names like:\n",
    "            [\"item\", \"unit\", \"wholesale_pettah_yesterday\", \n",
    "             \"wholesale_pettah_today\", ...]\n",
    "    \"\"\"\n",
    "    \n",
    "    # â”€â”€â”€ Combine first 50 lines and make lowercase â”€â”€â”€\n",
    "    # We only check the beginning because location names appear at the top\n",
    "    first_50_lines = section_lines[:50]\n",
    "    combined_text = \" \".join(first_50_lines).lower()\n",
    "    \n",
    "    # â”€â”€â”€ Start with basic columns â”€â”€â”€\n",
    "    column_names = [\"item\", \"unit\"]\n",
    "    \n",
    "    # â”€â”€â”€ Define default locations â”€â”€â”€\n",
    "    # These are the markets where wholesale prices come from\n",
    "    wholesale_locations = [\"pettah\", \"marandagahamula\"]\n",
    "    \n",
    "    # These are the markets where retail (customer) prices come from\n",
    "    retail_locations = [\"pettah\", \"dambulla\", \"narahenpita\"]\n",
    "    \n",
    "    # â”€â”€â”€ Check if special market exists â”€â”€â”€\n",
    "    # Sometimes \"Marandagahamula\" market is included\n",
    "    # If it exists, add it right after Pettah\n",
    "    # if \"marandagahamula\" in combined_text:\n",
    "    #     wholesale_locations.insert(1, \"marandagahamula\")  # Insert at position 1\n",
    "    #     # Now list becomes: [\"pettah\", \"marandagahamula\", \"dambulla\"]\n",
    "    \n",
    "    # â”€â”€â”€ Build wholesale column names â”€â”€â”€\n",
    "    # For each wholesale market, add yesterday and today columns\n",
    "    for location in wholesale_locations:\n",
    "        column_names.append(f\"wholesale_{location}_yesterday\")\n",
    "        column_names.append(f\"wholesale_{location}_today\")\n",
    "    \n",
    "    # Example result so far:\n",
    "    # [\"item\", \"unit\", \"wholesale_pettah_yesterday\", \"wholesale_pettah_today\",\n",
    "    #  \"wholesale_dambulla_yesterday\", \"wholesale_dambulla_today\"]\n",
    "    \n",
    "    # â”€â”€â”€ Build retail column names â”€â”€â”€\n",
    "    # For each retail market, add yesterday and today columns\n",
    "    for location in retail_locations:\n",
    "        column_names.append(f\"retail_{location}_yesterday\")\n",
    "        column_names.append(f\"retail_{location}_today\")\n",
    "    \n",
    "    # Final result:\n",
    "    # [\"item\", \"unit\", \n",
    "    #  \"wholesale_pettah_yesterday\", \"wholesale_pettah_today\",\n",
    "    #  \"wholesale_dambulla_yesterday\", \"wholesale_dambulla_today\",\n",
    "    #  \"retail_pettah_yesterday\", \"retail_pettah_today\",\n",
    "    #  \"retail_dambulla_yesterday\", \"retail_dambulla_today\",\n",
    "    #  \"retail_narahenpita_yesterday\", \"retail_narahenpita_today\"]\n",
    "    \n",
    "    return column_names\n",
    "\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# PART 4: Extract Section from PDF and Parse It\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def extract_and_parse_rice(pdf_path, start_word=\"RICE\", end_word=\"FISH\", page_number=2):\n",
    "    \"\"\"\n",
    "    Extracts the RICE section from a PDF and converts it to a table with smart column names.\n",
    "    \n",
    "    This function does three things:\n",
    "        1. Finds and extracts text between \"RICE\" and \"FISH\" in the PDF\n",
    "        2. Parses that text into a clean DataFrame\n",
    "        3. Adds meaningful column names based on detected locations\n",
    "    \n",
    "    Parameters:\n",
    "        pdf_path: Path to the PDF file\n",
    "        start_word: Word that marks the beginning of the section (default: \"RICE\")\n",
    "        end_word: Word that marks the end of the section (default: \"FISH\")\n",
    "        page_number: Which page to look at (default: 2)\n",
    "    \n",
    "    Returns:\n",
    "        A pandas DataFrame with the parsed price data and smart column names\n",
    "    \"\"\"\n",
    "    \n",
    "    # NOTE: You need to define extract_section_between() function\n",
    "    # That function should read the PDF and return lines of text\n",
    "    section_lines = extract_section_between(pdf_path, start_word, end_word, page_number)\n",
    "    \n",
    "    # Parse the extracted lines into a DataFrame\n",
    "    df = parse_price_section(section_lines)\n",
    "    \n",
    "    # â”€â”€â”€ Add Smart Column Names â”€â”€â”€\n",
    "    # Generate meaningful column names based on locations\n",
    "    smart_columns = create_smart_column_names(section_lines)\n",
    "    \n",
    "    # Only use as many column names as we have columns in the DataFrame\n",
    "    # (Sometimes we have fewer columns than expected)\n",
    "    smart_columns = smart_columns[:len(df.columns)]\n",
    "    \n",
    "    # Replace the generic column names (Item, Unit, Col1, Col2...)\n",
    "    # with meaningful names (item, unit, wholesale_pettah_yesterday...)\n",
    "    df.columns = smart_columns\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# PART 5: Example Usage (How to Run This Code)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example 1: Test with sample data (no PDF needed)\n",
    "    # print(\"=\" * 60)\n",
    "    # print(\"EXAMPLE 1: Testing with sample data\")\n",
    "    # print(\"=\" * 60)\n",
    "    \n",
    "    # sample_lines = [\n",
    "    #     \"Samba Rs./kg 130.00 132.00 135.00 140.00\",\n",
    "    #     \"Nadu (White)\",\n",
    "    #     \"Rs./kg 125.00 128.00 130.00\",\n",
    "    #     \"Red Nadu Rs./kg 120.00 122.00 n.a. 125.00\",\n",
    "    #     \"Keeri Samba Rs./kg 140.00 145.00 150.00 155.00 160.00\"\n",
    "    # ]\n",
    "    \n",
    "    # result = parse_price_section(sample_lines)\n",
    "    # print(\"\\nğŸ“Š Parsed Table (with generic column names):\")\n",
    "    # print(result)\n",
    "    \n",
    "    # # Example 2: Test smart column naming\n",
    "    # print(\"\\n\" + \"=\" * 60)\n",
    "    # print(\"EXAMPLE 2: Testing smart column names\")\n",
    "    # print(\"=\" * 60)\n",
    "    \n",
    "    # # Add location info to sample data\n",
    "    # sample_with_locations = [\n",
    "    #     \"Price Data for Pettah, Dambulla, and Narahenpita markets\",\n",
    "    #     \"Samba Rs./kg 130.00 132.00 135.00 140.00 142.00 145.00\",\n",
    "    #     \"Nadu (White) Rs./kg 125.00 128.00 130.00 132.00 135.00 138.00\"\n",
    "    # ]\n",
    "    \n",
    "    # result2 = parse_price_section(sample_with_locations)\n",
    "    \n",
    "    # # Apply smart column names\n",
    "    # smart_cols = create_smart_column_names(sample_with_locations)\n",
    "    # smart_cols = smart_cols[:len(result2.columns)]\n",
    "    # result2.columns = smart_cols\n",
    "    \n",
    "    # print(\"\\nğŸ“Š Same data with smart column names:\")\n",
    "    # print(result2)\n",
    "    # print(\"\\nâœ¨ Notice how columns now show: wholesale_pettah_yesterday, etc.\")\n",
    "    \n",
    "    # Example 3: Parse from actual PDF (uncomment to use)\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"EXAMPLE 3: Parsing from PDF with smart columns\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    pdf_path = \"../data/raw/2024/2024-01-03.pdf\"\n",
    "    df_rice = extract_and_parse_rice(pdf_path)\n",
    "    \n",
    "    print(\"\\nâœ… DataFrame created successfully!\")\n",
    "    display(df_rice.head(10))\n",
    "    print(\"\\nğŸ“‹ Column Names:\")\n",
    "    print(list(df_rice.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0bb4cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rice_price_collector",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
